{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUs6go0MNDT5",
    "outputId": "4c70249f-592f-4c5e-cfa6-c2148249b8d1"
   },
   "source": [
    "## HAM experiment with  classification -> Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrcc1TUXSzzF",
    "tags": []
   },
   "source": [
    "## Installation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.75.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorboard) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (69.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: barbar in /opt/conda/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: torchsummary in /opt/conda/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: pytorch-ignite in /opt/conda/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: torch<3,>=1.3 in /opt/conda/lib/python3.11/site-packages (from pytorch-ignite) (2.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pytorch-ignite) (24.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.15.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=1.3->pytorch-ignite) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.11/site-packages (1.0.20)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from timm) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from timm) (0.18.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from timm) (0.35.3)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (1.1.10)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "\n",
    "!pip install torch torchvision tensorboard\n",
    "!pip install barbar\n",
    "!pip install torchsummary\n",
    "!pip install pytorch-ignite\n",
    "!pip install timm\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9sq7HKYBo31x",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from shutil import copyfile, move\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from barbar import Bar\n",
    "from torchsummary import summary\n",
    "from ignite.metrics import Accuracy\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # Dataset for segmentation (HAM)\n",
    "    'train_dir_seg': '/home/jovyan/nfs/mgallazzi/datasets/SEGMENTATION_RESNET/images/training/',\n",
    "    'val_dir_seg': '/home/jovyan/nfs/mgallazzi/datasets/SEGMENTATION_RESNET/images/validation/',\n",
    "    'test_dir_seg': '/home/jovyan/nfs/mgallazzi/datasets/HAM_test_segmentation/test_images',\n",
    "\n",
    "    # Masks for segmentation (HAM)\n",
    "    'mask_dir_train': '/home/jovyan/nfs/mgallazzi/datasets/SEGMENTATION_RESNET/masks/training/',\n",
    "    'mask_dir_val': '/home/jovyan/nfs/mgallazzi/datasets/SEGMENTATION_RESNET/masks/validation/',\n",
    "    'mask_dir_test': '/home/jovyan/nfs/mgallazzi/datasets/HAM_test_segmentation/test_masks',\n",
    "\n",
    "    # Dataset for classification (HAM)\n",
    "    'train_dir_class': '/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/training/',\n",
    "    'val_dir_class': '/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/validation/',  \n",
    "    'test_dir_class': '/home/jovyan/nfs/mgallazzi/datasets/HAM10k_test_Duplicati/divided/',\n",
    "\n",
    "    'save_dir': 'experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg',\n",
    "    'num_classes': 7,  # Number of class for classification\n",
    "    'lambda_multi': 1.0,  # weight for multiclass-loss\n",
    "    'lambda_bin': 1.0,  # weight for binary-loss\n",
    "    'batch_size': 128,  # Batch size for training\n",
    "    'early_stopping': 20,  # Number of epochs for early stopping\n",
    "    'lr': 0.0001,  # Learning rate\n",
    "    'alpha': 0.25,  # Specific parameter for the loss weighting\n",
    "    'device': torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(args['save_dir']):\n",
    "    raise Exception(f\"Sorry, the output dir {args['save_dir']} already exists!\")  # error...\n",
    "os.makedirs(args['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, column_names):\n",
    "        column_names.insert(0, \"time_stamp\")\n",
    "        self.df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    def add_row(self, row_list):\n",
    "        row_list.insert(0, str(dt.datetime.now()))\n",
    "        # print(row_list)\n",
    "        self.df.loc[len(self.df)] = row_list\n",
    "\n",
    "    def save_to_csv(self, filepath):\n",
    "        self.df.to_csv(filepath, index=False)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        # Load data from the CSV file into the DataFrame\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def get_best_value(self, column_name):\n",
    "        if column_name in self.df.columns:\n",
    "            return self.df[column_name].max()\n",
    "        else:\n",
    "            raise ValueError(f\"Column '{column_name}' does not exist in the DataFrame\")\n",
    "\n",
    "    def plot(self, col_names=[], title=\"\", x_label=\"\", y_label=\"\", bottom=None, top=None):\n",
    "        data2plot = self.df[col_names]\n",
    "        # ================plot===================\n",
    "        ax = data2plot.plot(title=title) #figsize=(10,8), \n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_ylim(bottom, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIg7C2rTSzzJ",
    "tags": []
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/training/0.MEL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m val_images \u001b[38;5;241m=\u001b[39m count_files_by_category(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_dir_seg\u001b[39m\u001b[38;5;124m'\u001b[39m], categories)\n\u001b[1;32m     20\u001b[0m val_masks \u001b[38;5;241m=\u001b[39m count_files_by_category(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_dir_val\u001b[39m\u001b[38;5;124m'\u001b[39m], categories)\n\u001b[0;32m---> 21\u001b[0m train_classification \u001b[38;5;241m=\u001b[39m \u001b[43mcount_files_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_dir_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m val_classification \u001b[38;5;241m=\u001b[39m count_files_by_category(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_dir_class\u001b[39m\u001b[38;5;124m'\u001b[39m], categories)\n\u001b[1;32m     23\u001b[0m test_classification \u001b[38;5;241m=\u001b[39m count_files_by_category(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_dir_class\u001b[39m\u001b[38;5;124m'\u001b[39m], categories)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mcount_files_by_category\u001b[0;34m(base_dir, categories)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories:\n\u001b[1;32m      5\u001b[0m     dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, category)\n\u001b[0;32m----> 6\u001b[0m     count_by_category[category] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(dir_path))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m count_by_category\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/training/0.MEL'"
     ]
    }
   ],
   "source": [
    "# Function to count files in a folder by category\n",
    "def count_files_by_category(base_dir, categories):\n",
    "    count_by_category = {}\n",
    "    for category in categories:\n",
    "        dir_path = os.path.join(base_dir, category)\n",
    "        count_by_category[category] = len(os.listdir(dir_path))\n",
    "    return count_by_category\n",
    "\n",
    "# Function to count all files in a folder (no categories)\n",
    "def count_total_files(folder):\n",
    "    return len(os.listdir(folder))\n",
    "\n",
    "# Define the categories\n",
    "categories = ['0.MEL', '1.NV', '2.BCC', '3.AKIEC', '4.BKL', '5.DF', '6.VASC']\n",
    "\n",
    "# Count images and masks for training and validation sets\n",
    "train_images = count_files_by_category(args['train_dir_seg'], categories)\n",
    "train_masks = count_files_by_category(args['mask_dir_train'], categories)\n",
    "val_images = count_files_by_category(args['val_dir_seg'], categories)\n",
    "val_masks = count_files_by_category(args['mask_dir_val'], categories)\n",
    "train_classification = count_files_by_category(args['train_dir_class'], categories)\n",
    "val_classification = count_files_by_category(args['val_dir_class'], categories)\n",
    "test_classification = count_files_by_category(args['test_dir_class'], categories)\n",
    "\n",
    "# Create a DataFrame for training and validation sets\n",
    "df_train_val = pd.DataFrame({\n",
    "    'Training Images Segmentation': train_images,\n",
    "    'Training Masks Segmentation': train_masks,\n",
    "    'Validation Images Segmentation': val_images,\n",
    "    'Validation Masks Segmentation': val_masks,\n",
    "    'Training Images Classification': train_classification,\n",
    "    'Validation Images Classification': val_classification,\n",
    "    'Test Images Classification': test_classification,\n",
    "})\n",
    "\n",
    "# Count images and masks for test set (no categories)\n",
    "test_images_total = count_total_files(args['test_dir_seg'])\n",
    "test_masks_total = count_total_files(args['mask_dir_test'])\n",
    "\n",
    "# Create a separate DataFrame for the test set\n",
    "df_test = pd.DataFrame({\n",
    "    'Test Images': [test_images_total],\n",
    "    'Test Masks': [test_masks_total]\n",
    "})\n",
    "\n",
    "# Display the two tables\n",
    "print(\"Training and Validation Sets\")\n",
    "display(df_train_val)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione della mappatura delle classi binarie dove 1:maligne , 0:benigne\n",
    "class_mapping = {\n",
    "    '0.MEL': 1, '1.NV': 0, '2.BCC': 1, '3.AKIEC': 1,\n",
    "    '4.BKL': 0, '5.DF': 0, '6.VASC': 0\n",
    "}\n",
    "\n",
    "# Custom Dataset per ImageFolder with binary labels\n",
    "class BinaryImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, binary=True, multi=True):\n",
    "        super(BinaryImageFolder, self).__init__(root, transform=transform)\n",
    "        self.binary = binary\n",
    "        self.multiclass = multi\n",
    "        #self.dataset = datasets.ImageFolder(root, transform=transform)\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "        print(\"***Loading:\" + root)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label_multiclass = super(BinaryImageFolder, self).__getitem__(index)\n",
    "        class_name = self.idx_to_class[label_multiclass]\n",
    "        label_binaria = class_mapping[class_name]\n",
    "        return image, label_multiclass, label_binaria\n",
    "\n",
    "\n",
    "class BinaryOnlyImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, binary=True, multi=False):\n",
    "        super(BinaryOnlyImageFolder, self).__init__(root, transform=transform)\n",
    "        self.binary = binary\n",
    "        self.multiclass = multi\n",
    "        print(\"***Loading:\" + root)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label_binary = super(BinaryOnlyImageFolder, self).__getitem__(index)\n",
    "        return image, -1, label_binary\n",
    "\n",
    "\n",
    "class MyConcatDataset(ConcatDataset):\n",
    "    def __init__(self, datasets, binary=True, multi=True):\n",
    "        super(MyConcatDataset, self).__init__(datasets)\n",
    "        self.binary = binary\n",
    "        self.multiclass = multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxinrQSDpFLS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomResize:\n",
    "    def __init__(self, resize_min=224, resize_max=280):\n",
    "        self.resize_min = resize_min\n",
    "        self.resize_max = resize_max\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Randomly choose the resize dimensions\n",
    "        resize_size = random.randint(self.resize_min, self.resize_max)\n",
    "        resize_transforms = transforms.Resize(resize_size)\n",
    "        img = resize_transforms(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    RandomResize(224, 280), # transforms.Resize((224, 280)),  # Aumento delle dimensioni a 224x300\n",
    "    transforms.RandomCrop((224, 224)),  # Applicazione di RandomCrop\n",
    "    # transforms.Resize((224, 280)),\n",
    "    # transforms.CenterCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))], p=0.5),  \n",
    "\n",
    "    # La traslazione sar√† casuale con un range di +/-10% rispetto alle dimensioni originali\n",
    "    transforms.RandomApply(transforms=[transforms.RandomRotation(degrees=(-180, 180))], p=0.99),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 280)),  # Aumento delle dimensioni a 224x300\n",
    "    transforms.RandomCrop((224, 224)),  # Applicazione di RandomCrop\n",
    "    # transforms.Resize((224, 280)),\n",
    "    # torchvision.transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(224), #(224, 300)),  # PERCHE' IL RESIZE E' DIVERSO DAL VAL?\n",
    "    torchvision.transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def run_test_datasets():\n",
    "    # Dataset di classificazione per il training\n",
    "    train_dataset = BinaryImageFolder(\n",
    "        args['train_dir_class'], transform=train_transforms, binary=True, multi=True)\n",
    "    \n",
    "    # Dataset di classificazione per la validazione\n",
    "    val_dataset = BinaryImageFolder(\n",
    "        args['val_dir_class'], transform=val_transforms, binary=True, multi=True)\n",
    "    \n",
    "    # Dataset di classificazione per il test\n",
    "    test_dataset = BinaryImageFolder(\n",
    "        args['test_dir_class'], transform=test_transforms, binary=True, multi=True)\n",
    "\n",
    "    # Creare DataLoader per classificazione\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Esegui la funzione per creare i loader\n",
    "train_loader, val_loader, test_loader = run_test_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "\n",
    "class ComposeTwo(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class RandomResizeCrop:\n",
    "    def __init__(self, size=(224,224), resize_min=224, resize_max=280):\n",
    "        self.size = size\n",
    "        self.resize_min = resize_min\n",
    "        self.resize_max = resize_max\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        new_size = random.randint(self.resize_min, self.resize_max)\n",
    "        image = TF.resize(image, (new_size, new_size))\n",
    "        if mask is not None:\n",
    "            mask = TF.resize(mask, (new_size, new_size), interpolation=Image.NEAREST)\n",
    "        \n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=self.size)\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        if mask is not None:\n",
    "            mask = TF.crop(mask, i, j, h, w)\n",
    "        return image, mask    \n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() < self.p:\n",
    "            image = TF.hflip(image)\n",
    "            if mask is not None:\n",
    "                mask = TF.hflip(mask)\n",
    "        return image, mask\n",
    "\n",
    "class RandomAffine:\n",
    "    def __init__(self, degrees, translate):\n",
    "        self.degrees = degrees\n",
    "        self.translate = translate\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        params = transforms.RandomAffine.get_params(self.degrees, self.translate, None, None, image.size)\n",
    "        image = TF.affine(image, *params)\n",
    "        if mask is not None:\n",
    "            mask = TF.affine(mask, *params)\n",
    "        return image, mask\n",
    "\n",
    "class RandomRotation:\n",
    "    def __init__(self, degrees):\n",
    "        self.degrees = degrees\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        angle = random.uniform(self.degrees[0], self.degrees[1])\n",
    "        image = TF.rotate(image, angle)\n",
    "        if mask is not None:\n",
    "            mask = TF.rotate(mask, angle)\n",
    "        return image, mask\n",
    "\n",
    "class ToTensorAndNormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(mean, std)\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        image = self.to_tensor(image)\n",
    "        image = self.normalize(image)\n",
    "        if mask is not None:\n",
    "            mask = self.to_tensor(mask)\n",
    "        return image, mask\n",
    "\n",
    "# Dataset per training e validazione (con sottocartelle)\n",
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Directory con le immagini di input, con sottocartelle.\n",
    "            mask_dir (str): Directory con le maschere di segmentazione, con sottocartelle.\n",
    "            transform (callable, optional): Trasformazioni da applicare sia alle immagini di input che alle maschere.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Estensioni supportate\n",
    "        valid_extensions = ('.png', '.bmp', '.jpg', '.jpeg', '.tiff')\n",
    "\n",
    "        # Cerca immagini e maschere nelle sottocartelle rispettando la stessa struttura\n",
    "        self.image_filenames = []\n",
    "        self.mask_filenames = []\n",
    "\n",
    "        for class_folder in os.listdir(image_dir):\n",
    "            class_image_folder = os.path.join(image_dir, class_folder)\n",
    "            class_mask_folder = os.path.join(mask_dir, class_folder)\n",
    "\n",
    "            # Verifica che le sottocartelle esistano sia per le immagini che per le maschere\n",
    "            if not os.path.exists(class_mask_folder):\n",
    "                raise ValueError(f\"Missing corresponding mask folder for {class_folder}\")\n",
    "\n",
    "            for image_file in os.listdir(class_image_folder):\n",
    "                if image_file.endswith(valid_extensions):\n",
    "                    image_path = os.path.join(class_image_folder, image_file)\n",
    "                    mask_path = os.path.join(class_mask_folder, image_file.replace('.jpg', '.png'))\n",
    "\n",
    "                    # Aggiungi solo se esistono sia immagine che maschera\n",
    "                    if os.path.exists(mask_path):\n",
    "                        self.image_filenames.append(image_path)\n",
    "                        self.mask_filenames.append(mask_path)\n",
    "                    else:\n",
    "                        print(f\"Maschera non trovata per {image_file}, saltata.\")\n",
    "\n",
    "        if len(self.image_filenames) == 0:\n",
    "            raise ValueError(f\"Nessuna immagine trovata nella directory: {image_dir}\")\n",
    "        if len(self.mask_filenames) == 0:\n",
    "            raise ValueError(f\"Nessuna maschera trovata nella directory: {mask_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_filenames[idx]\n",
    "        mask_path = self.mask_filenames[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Converti la maschera in scala di grigi\n",
    "\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Dataset for the test set (no subdirectories by class)\n",
    "class TestImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "\n",
    "        # Load all images and corresponding masks\n",
    "        for image_file in os.listdir(image_dir):\n",
    "            # Only consider .jpg files for the images\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "                # The mask file has a .png extension and includes \"_segmentation\"\n",
    "                mask_file = image_file.replace('.jpg', '_segmentation.png')\n",
    "                mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "                # Append only if both the image and the mask exist\n",
    "                if os.path.exists(mask_path):\n",
    "                    self.images.append(image_path)\n",
    "                    self.masks.append(mask_path)\n",
    "                else:\n",
    "                    print(f\"Mask not found for {image_file}, skipping.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert(\"RGB\")\n",
    "        mask = Image.open(self.masks[idx]).convert(\"L\")  # Convert the mask to grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test_seg_dataset():\n",
    "    # Definire le trasformazioni\n",
    "    seg_transform = ComposeTwo([\n",
    "        RandomResizeCrop((224, 224), resize_min=224, resize_max=280),\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "        RandomAffine(degrees=(-10,10), translate=(0.1, 0.1)),\n",
    "        RandomRotation(degrees=(-180, 180)),\n",
    "        ToTensorAndNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Dataset di segmentazione per il training\n",
    "    train_segmentation_dataset = CustomSegmentationDataset(\n",
    "        args['train_dir_seg'], args['mask_dir_train'], transform=seg_transform)\n",
    "\n",
    "    # Dataset di segmentazione per la validazione\n",
    "    val_segmentation_dataset = CustomSegmentationDataset(\n",
    "        args['val_dir_seg'], args['mask_dir_val'], transform=seg_transform)\n",
    "\n",
    "    # Dataset di segmentazione per il test (senza sottocartelle e con \"_segmentation\" nelle maschere)\n",
    "    test_segmentation_dataset = TestImageSegmentationDataset(\n",
    "        args['test_dir_seg'], args['mask_dir_test'], transform=seg_transform)\n",
    "\n",
    "    # Creare DataLoader per segmentazione\n",
    "    train_segmentation_loader = DataLoader(train_segmentation_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=8)\n",
    "    val_segmentation_loader = DataLoader(val_segmentation_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "    test_segmentation_loader = DataLoader(test_segmentation_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "\n",
    "    # Esegui un esempio per verificare la forma delle immagini e delle maschere\n",
    "    image, mask = train_segmentation_dataset.__getitem__(0)  # Ottieni il primo esempio dal dataset di training\n",
    "    print(f\"Forma dell'immagine (training): {image.shape}\")\n",
    "    print(f\"Forma della maschera (training): {mask.shape}\")\n",
    "\n",
    "    image, mask = test_segmentation_dataset.__getitem__(0)  # Ottieni il primo esempio dal dataset di test\n",
    "    print(f\"Forma dell'immagine (test): {image.shape}\")\n",
    "    print(f\"Forma della maschera (test): {mask.shape}\")\n",
    "\n",
    "    return train_segmentation_loader, val_segmentation_loader, test_segmentation_loader\n",
    "\n",
    "# Esegui la funzione per creare i loader di segmentazione e verifica le forme\n",
    "train_segmentation_loader, val_segmentation_loader, test_segmentation_loader = run_test_seg_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWhSCQygSzzU",
    "tags": []
   },
   "source": [
    "## Models for classification and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timm.models.layers import SelectAdaptivePool2d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SwinBase(nn.Module):\n",
    "    def __init__(self, base_model=None):\n",
    "        super(SwinBase, self).__init__()\n",
    "        if base_model is None:\n",
    "            self.base = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
    "            self.head_in = self.base.head.in_features\n",
    "            self.base.head = nn.Identity()\n",
    "        else:\n",
    "            self.base = base_model.base\n",
    "            self.head_in = base_model.head_in\n",
    "\n",
    "    def load_weights(self, checkpoint_path):\n",
    "        print(\"Loading pre-trained:\", checkpoint_path)\n",
    "        self.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    def save_weights(self, save_path):\n",
    "        print(\"Saving model:\", save_path)\n",
    "        torch.save(self.state_dict(), save_path)\n",
    "\n",
    "\n",
    "class SwinSeg(SwinBase):\n",
    "    def __init__(self, base_model=None):\n",
    "        super(SwinSeg, self).__init__(base_model)\n",
    "\n",
    "        # Creare un modulo Sequential per l'upsampling\n",
    "        self.head = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.head_in, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.permute(0, 3, 1, 2)  # Diventa [batch, 1536, 7, 7]\n",
    "        x = self.head(x)\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "    def convert_to_classification(self, num_classes_multiclass=7, num_classes_binary=2):\n",
    "        return SwinClassification(base_model=self, num_classes_multiclass=num_classes_multiclass, num_classes_binary=num_classes_binary)\n",
    "\n",
    "\n",
    "class PermuteDimensions(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "class SwinClassification(SwinBase):\n",
    "    def __init__(self, base_model=None, num_classes_multiclass=7, num_classes_binary=2):\n",
    "        super(SwinClassification, self).__init__(base_model)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            #SelectAdaptivePool2d(output_size=1, pool_type='avg', flatten=False),\n",
    "            PermuteDimensions(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(1),\n",
    "            nn.Dropout(p=0.0, inplace=False),\n",
    "            nn.Linear(self.head_in, num_classes_multiclass),\n",
    "            nn.Linear(num_classes_multiclass, num_classes_binary)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.head[0:4](x)\n",
    "        x_multiclass = self.head[4](x)\n",
    "        x_binary = self.head[5](x_multiclass)\n",
    "        return x_multiclass, x_binary\n",
    "\n",
    "    def convert_to_segmentation(self):\n",
    "        return SwinSeg(base_model=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "    #segmentation_model\n",
    "    seg_model = SwinSeg()\n",
    "    seg_model_path = os.path.join(args['save_dir'], 'seg_model.pth')\n",
    "    out = seg_model(input_tensor)\n",
    "    print(\"out seg:\", out.shape)\n",
    "\n",
    "    seg_model.save_weights(seg_model_path)\n",
    "    seg_model.load_weights(seg_model_path)\n",
    "\n",
    "    # convert segmentation model into classification model\n",
    "    cls_model = seg_model.convert_to_classification()\n",
    "    cls_model_path = os.path.join(args['save_dir'], 'cls_model.pth')\n",
    "    out1, out2 = cls_model(input_tensor)\n",
    "    print(\"out multi:\", out1.shape)\n",
    "    print(\"out bin:\", out2.shape)\n",
    "    \n",
    "    cls_model.save_weights(cls_model_path)\n",
    "    cls_model.load_weights(cls_model_path)\n",
    "\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Compare the training results when three different combinations of data are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "device = args['device']\n",
    "\n",
    "criterion_multi = nn.CrossEntropyLoss()\n",
    "criterion_binaria = nn.CrossEntropyLoss() #nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per salvare la Confusion Matrix come immagine\n",
    "def plot_and_save_confusion_matrix(labels, preds, class_names, model_name, save_dir):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion Matrix ({model_name})')\n",
    "    \n",
    "    # Salva la matrice di confusione come immagine\n",
    "    cm_path = os.path.join(save_dir, f'confusion_matrix_{model_name}.png')\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix salvata in: {cm_path}\")\n",
    "\n",
    "# Funzione per tracciare e salvare i grafici di loss e accuracy\n",
    "def plot_and_save_metrics(metrics, save_dir):\n",
    "    epochs = metrics['epoch']\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['train_loss_bin'], label='Train Loss Bin')\n",
    "    plt.plot(epochs, metrics['val_loss_bin'], label='Val Loss Bin')\n",
    "    plt.plot(epochs, metrics['test_loss_bin'], label='Test Loss Bin')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Binary Loss over Epochs')\n",
    "    plt.legend()\n",
    "    loss_plot_path = os.path.join(save_dir, 'loss_plot.png')\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Loss plot salvato in: {loss_plot_path}\")\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics['train_acc_bin'], label='Train Acc Bin')\n",
    "    plt.plot(epochs, metrics['val_acc_bin'], label='Val Acc Bin')\n",
    "    plt.plot(epochs, metrics['test_acc_bin'], label='Test Acc Bin')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Binary Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    acc_plot_path = os.path.join(save_dir, 'accuracy_plot.png')\n",
    "    plt.savefig(acc_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Accuracy plot salvato in: {acc_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "n3of0fhypE8O",
    "outputId": "94a44f1b-92b2-46f7-b60e-2f7fad958193",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funzioni di training e validazione\n",
    "def train_one_epoch(model, train_loader, optimizer, device):\n",
    "    print('Start training...')\n",
    "    model.train()\n",
    "    running_loss_multi = 0.0\n",
    "    running_loss_binaria = 0.0\n",
    "    correct_multi = torch.tensor(0).to(device)\n",
    "    correct_bin = torch.tensor(0).to(device)\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels_multi, labels_bin in train_loader:\n",
    "        inputs, labels_multi = inputs.to(device), labels_multi.to(device)\n",
    "        labels_bin = labels_bin.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        multiclass_output, binary_output = model(inputs)\n",
    "\n",
    "        comb_loss = 0\n",
    "        # Loss multi-classe\n",
    "        if train_loader.dataset.multiclass:\n",
    "            loss_multi = criterion_multi(multiclass_output, labels_multi)\n",
    "            comb_loss += args[\"lambda_multi\"] * loss_multi \n",
    "\n",
    "        # Loss binaria\n",
    "        if train_loader.dataset.binary:\n",
    "            loss_binaria = criterion_binaria(binary_output, labels_bin)\n",
    "            comb_loss += args[\"lambda_bin\"] * loss_binaria\n",
    "\n",
    "        comb_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        if train_loader.dataset.multiclass:\n",
    "            running_loss_multi += loss_multi.item()\n",
    "            _, predicted_multi = torch.max(multiclass_output, dim=1)\n",
    "            correct_multi += (predicted_multi.view(labels_multi.size()).data == labels_multi.data).sum()\n",
    "\n",
    "        if train_loader.dataset.binary:\n",
    "            running_loss_binaria += loss_binaria.item()\n",
    "            _, predicted_bin = torch.max(binary_output, dim=1)\n",
    "            correct_bin += (predicted_bin.view(labels_bin.size()).data == labels_bin.data).sum()\n",
    "\n",
    "        total += labels_multi.size(0)\n",
    "\n",
    "    train_loss_multi = running_loss_multi / len(train_loader)\n",
    "    train_loss_binaria = running_loss_binaria / len(train_loader)\n",
    "    train_acc_multi = correct_multi / total\n",
    "    train_acc_bin = correct_bin / total\n",
    "    return train_loss_multi, train_loss_binaria, train_acc_multi.cpu().item(), train_acc_bin.cpu().item()\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    print('Start validation...')\n",
    "    model.eval()\n",
    "    running_loss_multi = 0.0\n",
    "    running_loss_binaria = 0.0\n",
    "    correct_multi = torch.tensor(0).to(device)\n",
    "    correct_bin = torch.tensor(0).to(device)\n",
    "    total_multi = 0\n",
    "    total_bin = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels_multi, labels_bin in val_loader:\n",
    "            inputs, labels_multi = inputs.to(device), labels_multi.to(device)\n",
    "            labels_bin = labels_bin.to(device)\n",
    "\n",
    "            multiclass_output, binary_output = model(inputs)\n",
    "\n",
    "            # Loss multi-classe\n",
    "            if val_loader.dataset.multiclass:\n",
    "                loss_multi = criterion_multi(multiclass_output, labels_multi)\n",
    "                running_loss_multi += loss_multi.item()\n",
    "                _, predicted_multi = torch.max(multiclass_output, dim=1)\n",
    "                correct_multi += (predicted_multi.view(labels_multi.size()).data == labels_multi.data).sum()\n",
    "                total_multi += labels_multi.size(0)\n",
    "                all_labels.extend(labels_multi.cpu().numpy())\n",
    "                all_predictions.extend(predicted_multi.cpu().numpy())\n",
    "\n",
    "            # Loss binaria\n",
    "            if val_loader.dataset.binary:\n",
    "                loss_binaria = criterion_binaria(binary_output, labels_bin)\n",
    "                running_loss_binaria += loss_binaria.item()\n",
    "                _, predicted_bin = torch.max(binary_output, dim=1)\n",
    "                correct_bin += (predicted_bin.view(labels_bin.size()).data == labels_bin.data).sum()\n",
    "                total_bin += labels_bin.size(0)\n",
    "\n",
    "    val_loss_multi = running_loss_multi / total_multi if total_multi > 0 else 0\n",
    "    val_loss_binaria = running_loss_binaria / total_bin if total_bin > 0 else 0\n",
    "\n",
    "    # Verifica se val_acc_multi_filtered e val_acc_bin sono tensori prima di usare .cpu().item()\n",
    "    if isinstance(correct_multi, torch.Tensor):\n",
    "        val_acc_multi_filtered = correct_multi / total_multi if total_multi > 0 else 0\n",
    "        val_acc_multi_filtered = val_acc_multi_filtered.cpu().item() if torch.is_tensor(val_acc_multi_filtered) else val_acc_multi_filtered\n",
    "    else:\n",
    "        val_acc_multi_filtered = correct_multi / total_multi if total_multi > 0 else correct_multi\n",
    "\n",
    "    if isinstance(correct_bin, torch.Tensor):\n",
    "        val_acc_bin = correct_bin / total_bin if total_bin > 0 else 0\n",
    "        val_acc_bin = val_acc_bin.cpu().item() if torch.is_tensor(val_acc_bin) else val_acc_bin\n",
    "    else:\n",
    "        val_acc_bin = correct_bin / total_bin if total_bin > 0 else correct_bin\n",
    "\n",
    "    return val_loss_multi, val_loss_binaria, val_acc_multi_filtered, val_acc_bin, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Loading:/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/training/\n",
      "***Loading:/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/validation/\n",
      "***Loading:/home/jovyan/nfs/mgallazzi/datasets/HAM10k_test_Duplicati/divided/\n",
      "\n",
      "Numero di esempi nel dataset di training: 6968\n",
      "Inizializzazione di un nuovo modello di classificazione...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 1, Loss Train Bin: 0.3546, Acc Train Bin: 0.8175, Loss Val Bin: 0.0023, Acc Val Bin: 0.8711, Loss Test Bin: 0.0023, Acc Test Bin: 0.8657\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 2, Loss Train Bin: 0.2651, Acc Train Bin: 0.8756, Loss Val Bin: 0.0020, Acc Val Bin: 0.8934, Loss Test Bin: 0.0022, Acc Test Bin: 0.8882\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 3, Loss Train Bin: 0.2150, Acc Train Bin: 0.9049, Loss Val Bin: 0.0014, Acc Val Bin: 0.9244, Loss Test Bin: 0.0018, Acc Test Bin: 0.9001\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 4, Loss Train Bin: 0.1747, Acc Train Bin: 0.9264, Loss Val Bin: 0.0013, Acc Val Bin: 0.9238, Loss Test Bin: 0.0021, Acc Test Bin: 0.8928\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 5, Loss Train Bin: 0.1496, Acc Train Bin: 0.9383, Loss Val Bin: 0.0008, Acc Val Bin: 0.9536, Loss Test Bin: 0.0019, Acc Test Bin: 0.9027\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 6, Loss Train Bin: 0.1211, Acc Train Bin: 0.9513, Loss Val Bin: 0.0007, Acc Val Bin: 0.9679, Loss Test Bin: 0.0027, Acc Test Bin: 0.8802\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 7, Loss Train Bin: 0.0932, Acc Train Bin: 0.9627, Loss Val Bin: 0.0006, Acc Val Bin: 0.9719, Loss Test Bin: 0.0027, Acc Test Bin: 0.9073\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 8, Loss Train Bin: 0.0832, Acc Train Bin: 0.9667, Loss Val Bin: 0.0005, Acc Val Bin: 0.9788, Loss Test Bin: 0.0025, Acc Test Bin: 0.8921\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 9, Loss Train Bin: 0.0639, Acc Train Bin: 0.9759, Loss Val Bin: 0.0004, Acc Val Bin: 0.9799, Loss Test Bin: 0.0028, Acc Test Bin: 0.8789\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 10, Loss Train Bin: 0.0583, Acc Train Bin: 0.9782, Loss Val Bin: 0.0005, Acc Val Bin: 0.9805, Loss Test Bin: 0.0032, Acc Test Bin: 0.9001\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 11, Loss Train Bin: 0.0517, Acc Train Bin: 0.9832, Loss Val Bin: 0.0002, Acc Val Bin: 0.9914, Loss Test Bin: 0.0028, Acc Test Bin: 0.8981\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 12, Loss Train Bin: 0.0423, Acc Train Bin: 0.9851, Loss Val Bin: 0.0001, Acc Val Bin: 0.9960, Loss Test Bin: 0.0026, Acc Test Bin: 0.9080\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Miglior Acc Test Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 13, Loss Train Bin: 0.0340, Acc Train Bin: 0.9869, Loss Val Bin: 0.0002, Acc Val Bin: 0.9914, Loss Test Bin: 0.0030, Acc Test Bin: 0.8895\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 14, Loss Train Bin: 0.0364, Acc Train Bin: 0.9862, Loss Val Bin: 0.0001, Acc Val Bin: 0.9937, Loss Test Bin: 0.0033, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 15, Loss Train Bin: 0.0228, Acc Train Bin: 0.9927, Loss Val Bin: 0.0001, Acc Val Bin: 0.9960, Loss Test Bin: 0.0036, Acc Test Bin: 0.9021\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 16, Loss Train Bin: 0.0182, Acc Train Bin: 0.9944, Loss Val Bin: 0.0001, Acc Val Bin: 0.9914, Loss Test Bin: 0.0033, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 17, Loss Train Bin: 0.0219, Acc Train Bin: 0.9924, Loss Val Bin: 0.0001, Acc Val Bin: 0.9954, Loss Test Bin: 0.0037, Acc Test Bin: 0.8921\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 18, Loss Train Bin: 0.0102, Acc Train Bin: 0.9958, Loss Val Bin: 0.0000, Acc Val Bin: 0.9983, Loss Test Bin: 0.0043, Acc Test Bin: 0.9021\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 19, Loss Train Bin: 0.0075, Acc Train Bin: 0.9973, Loss Val Bin: 0.0001, Acc Val Bin: 0.9960, Loss Test Bin: 0.0045, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 20, Loss Train Bin: 0.0097, Acc Train Bin: 0.9963, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0043, Acc Test Bin: 0.9007\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 21, Loss Train Bin: 0.0089, Acc Train Bin: 0.9971, Loss Val Bin: 0.0001, Acc Val Bin: 0.9977, Loss Test Bin: 0.0041, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 22, Loss Train Bin: 0.0135, Acc Train Bin: 0.9957, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0044, Acc Test Bin: 0.8895\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 23, Loss Train Bin: 0.0131, Acc Train Bin: 0.9956, Loss Val Bin: 0.0001, Acc Val Bin: 0.9977, Loss Test Bin: 0.0044, Acc Test Bin: 0.8934\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 24, Loss Train Bin: 0.0075, Acc Train Bin: 0.9980, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0044, Acc Test Bin: 0.8968\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 25, Loss Train Bin: 0.0074, Acc Train Bin: 0.9980, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0042, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 26, Loss Train Bin: 0.0061, Acc Train Bin: 0.9977, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0045, Acc Test Bin: 0.8954\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 27, Loss Train Bin: 0.0049, Acc Train Bin: 0.9980, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0043, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 28, Loss Train Bin: 0.0050, Acc Train Bin: 0.9981, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0045, Acc Test Bin: 0.8948\n",
      "Miglior Acc Val Bin, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 29, Loss Train Bin: 0.0058, Acc Train Bin: 0.9980, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0047, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 30, Loss Train Bin: 0.0028, Acc Train Bin: 0.9989, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0045, Acc Test Bin: 0.8974\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 31, Loss Train Bin: 0.0021, Acc Train Bin: 0.9994, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0049, Acc Test Bin: 0.8987\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 32, Loss Train Bin: 0.0048, Acc Train Bin: 0.9984, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0056, Acc Test Bin: 0.8802\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 33, Loss Train Bin: 0.0047, Acc Train Bin: 0.9984, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0049, Acc Test Bin: 0.8948\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 34, Loss Train Bin: 0.0019, Acc Train Bin: 0.9994, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0048, Acc Test Bin: 0.8941\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 35, Loss Train Bin: 0.0021, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0050, Acc Test Bin: 0.8961\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 36, Loss Train Bin: 0.0027, Acc Train Bin: 0.9994, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0050, Acc Test Bin: 0.8901\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 37, Loss Train Bin: 0.0011, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0049, Acc Test Bin: 0.8954\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 38, Loss Train Bin: 0.0018, Acc Train Bin: 0.9994, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0047, Acc Test Bin: 0.8994\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 39, Loss Train Bin: 0.0013, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0049, Acc Test Bin: 0.8948\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 40, Loss Train Bin: 0.0049, Acc Train Bin: 0.9987, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0052, Acc Test Bin: 0.8981\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 41, Loss Train Bin: 0.0049, Acc Train Bin: 0.9989, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0052, Acc Test Bin: 0.8987\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 42, Loss Train Bin: 0.0034, Acc Train Bin: 0.9989, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0050, Acc Test Bin: 0.8941\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 43, Loss Train Bin: 0.0016, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0050, Acc Test Bin: 0.8981\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 44, Loss Train Bin: 0.0020, Acc Train Bin: 0.9991, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0051, Acc Test Bin: 0.8987\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 45, Loss Train Bin: 0.0017, Acc Train Bin: 0.9993, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0051, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 46, Loss Train Bin: 0.0017, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0049, Acc Test Bin: 0.9040\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 47, Loss Train Bin: 0.0008, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0051, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 48, Loss Train Bin: 0.0012, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0052, Acc Test Bin: 0.8987\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 49, Loss Train Bin: 0.0013, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0051, Acc Test Bin: 0.8948\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 50, Loss Train Bin: 0.0005, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0052, Acc Test Bin: 0.8948\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 51, Loss Train Bin: 0.0011, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0052, Acc Test Bin: 0.8961\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 52, Loss Train Bin: 0.0007, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0050, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 53, Loss Train Bin: 0.0018, Acc Train Bin: 0.9993, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0051, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 54, Loss Train Bin: 0.0013, Acc Train Bin: 0.9993, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0051, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 55, Loss Train Bin: 0.0006, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0051, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 56, Loss Train Bin: 0.0010, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0051, Acc Test Bin: 0.9040\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 57, Loss Train Bin: 0.0009, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 0.9989, Loss Test Bin: 0.0054, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 58, Loss Train Bin: 0.0004, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 59, Loss Train Bin: 0.0007, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9021\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 60, Loss Train Bin: 0.0002, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 61, Loss Train Bin: 0.0006, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9040\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 62, Loss Train Bin: 0.0017, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.8994\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 63, Loss Train Bin: 0.0014, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0052, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 64, Loss Train Bin: 0.0022, Acc Train Bin: 0.9993, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0052, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 65, Loss Train Bin: 0.0006, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 66, Loss Train Bin: 0.0008, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.8981\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 67, Loss Train Bin: 0.0007, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0053, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 68, Loss Train Bin: 0.0014, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.8994\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 69, Loss Train Bin: 0.0004, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.8994\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 70, Loss Train Bin: 0.0004, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 71, Loss Train Bin: 0.0008, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0053, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 72, Loss Train Bin: 0.0004, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 73, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 74, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9014\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 75, Loss Train Bin: 0.0006, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 76, Loss Train Bin: 0.0007, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0054, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 77, Loss Train Bin: 0.0010, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0053, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 78, Loss Train Bin: 0.0006, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 79, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0054, Acc Test Bin: 0.8994\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 80, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9007\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 81, Loss Train Bin: 0.0002, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9021\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 82, Loss Train Bin: 0.0004, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9001\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 83, Loss Train Bin: 0.0017, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 84, Loss Train Bin: 0.0008, Acc Train Bin: 0.9997, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9021\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 85, Loss Train Bin: 0.0005, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0054, Acc Test Bin: 0.9021\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 86, Loss Train Bin: 0.0002, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0054, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 87, Loss Train Bin: 0.0004, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0054, Acc Test Bin: 0.9047\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 88, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0054, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 89, Loss Train Bin: 0.0004, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0055, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 90, Loss Train Bin: 0.0003, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 91, Loss Train Bin: 0.0018, Acc Train Bin: 0.9996, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 92, Loss Train Bin: 0.0005, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9027\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 93, Loss Train Bin: 0.0002, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 94, Loss Train Bin: 0.0002, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 95, Loss Train Bin: 0.0001, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 96, Loss Train Bin: 0.0003, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 97, Loss Train Bin: 0.0003, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 98, Loss Train Bin: 0.0005, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0056, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 99, Loss Train Bin: 0.0003, Acc Train Bin: 0.9999, Loss Val Bin: 0.0000, Acc Val Bin: 0.9994, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 100, Loss Train Bin: 0.0001, Acc Train Bin: 1.0000, Loss Val Bin: 0.0000, Acc Val Bin: 1.0000, Loss Test Bin: 0.0055, Acc Test Bin: 0.9034\n",
      "Loss plot salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/loss_plot.png\n",
      "Accuracy plot salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/accuracy_plot.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completato.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Esegui la funzione per il training binario usando un nuovo modello di classificazione\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[43mrun_binary_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 105\u001b[0m, in \u001b[0;36mrun_binary_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Salva la confusion matrix\u001b[39;00m\n\u001b[1;32m    104\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass_n\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Sostituisci con i nomi delle classi\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[43mplot_and_save_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_test_bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msave_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m plot_and_save_confusion_matrix(val_labels, val_preds, class_names, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_val_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completato.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m, in \u001b[0;36mplot_and_save_confusion_matrix\u001b[0;34m(labels, preds, class_names, model_name, save_dir)\u001b[0m\n\u001b[1;32m      3\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, preds)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/seaborn/matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[1;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/seaborn/matrix.py:163\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mylabel \u001b[38;5;241m=\u001b[39m ylabel \u001b[38;5;28;01mif\u001b[39;00m ylabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Determine good default values for the colormapping\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_cmap_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Sort out the annotations\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/seaborn/matrix.py:202\u001b[0m, in \u001b[0;36m_HeatMapper._determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    200\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanpercentile(calc_data, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vmax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m robust:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:343\u001b[0m, in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    338\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    345\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    346\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funzione principale per il training binario\n",
    "def run_binary_training():\n",
    "    # Utilizza i dataset di classificazione definiti in args\n",
    "    train_dataset = BinaryImageFolder(\n",
    "        args['train_dir_class'], transform=train_transforms, binary=True, multi=False)\n",
    "    \n",
    "    val_dataset = BinaryImageFolder(\n",
    "        args['val_dir_class'], transform=val_transforms, binary=True, multi=False)\n",
    "    \n",
    "    test_dataset = BinaryImageFolder(\n",
    "        args['test_dir_class'], transform=test_transforms, binary=True, multi=False)\n",
    "    \n",
    "    # Creazione dei DataLoader per training, validazione e test\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "    \n",
    "    print(\"\\nNumero di esempi nel dataset di training:\", len(train_dataset))\n",
    "    \n",
    "    # Inizializza le metriche, il modello, l'ottimizzatore, ecc.\n",
    "    metrics = Metrics([\"epoch\", \"lr\", \n",
    "                       \"train_loss_mult\", \"train_loss_bin\", \n",
    "                       \"train_acc_multi\", \"train_acc_bin\", \n",
    "                       \"val_loss_multi\", \"val_loss_bin\", \n",
    "                       \"val_acc_multi\", \"val_acc_bin\",\n",
    "                       \"test_loss_multi\", \"test_loss_bin\",\n",
    "                       \"test_acc_multi\", \"test_acc_bin\",\n",
    "                       \"best_val_acc\"])\n",
    "    \n",
    "    # Non caricare il modello di segmentazione pre-addestrato, inizializza un nuovo modello di classificazione\n",
    "    print(\"Inizializzazione di un nuovo modello di classificazione...\")\n",
    "    model = SwinClassification(num_classes_multiclass=args['num_classes'], num_classes_binary=2)  # Modello di classificazione\n",
    "    \n",
    "    model = model.to(args['device'])\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    lambda_lr = lambda epoch: 0.95 ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_test_acc_bin = 0  # Per tracciare il miglior test acc binario\n",
    "    \n",
    "    for epoch in range(100):  # Imposta il numero di epoche\n",
    "        # Fase di training\n",
    "        train_loss_multi, train_loss_binaria, train_acc, train_acc_bin = train_one_epoch(\n",
    "            model, train_loader, optimizer, args['device'])\n",
    "        \n",
    "        # Fase di validazione\n",
    "        val_loss_multi, val_loss_binaria, val_acc_multi, val_acc_bin, val_labels, val_preds = validate(\n",
    "            model, val_loader, args['device'])\n",
    "        \n",
    "        # Fase di test\n",
    "        test_loss_multi, test_loss_binaria, test_acc_multi, test_acc_bin, test_labels, test_preds = validate(\n",
    "            model, test_loader, args['device'])\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoca {epoch+1}, Loss Train Bin: {train_loss_binaria:.4f}, '\n",
    "              f'Acc Train Bin: {train_acc_bin:.4f}, Loss Val Bin: {val_loss_binaria:.4f}, '\n",
    "              f'Acc Val Bin: {val_acc_bin:.4f}, Loss Test Bin: {test_loss_binaria:.4f}, '\n",
    "              f'Acc Test Bin: {test_acc_bin:.4f}')\n",
    "        \n",
    "        # Salva il modello se l'accuratezza di validazione binaria √® migliorata\n",
    "        if val_acc_bin > best_val_acc:\n",
    "            print(\"Miglior Acc Val Bin, salvataggio del modello...\")\n",
    "            best_val_acc = val_acc_bin\n",
    "            torch.save(model.state_dict(), os.path.join(args['save_dir'], f'model_best_val_bin.pt'))\n",
    "        \n",
    "        # Salva il modello se l'accuratezza di test binaria √® migliorata\n",
    "        if test_acc_bin > best_test_acc_bin:\n",
    "            print(\"Miglior Acc Test Bin, salvataggio del modello...\")\n",
    "            best_test_acc_bin = test_acc_bin\n",
    "            torch.save(model.state_dict(), os.path.join(args['save_dir'], f'model_best_test_bin.pt'))\n",
    "        \n",
    "        # Salva il modello ad ogni epoca\n",
    "        torch.save(model.state_dict(), os.path.join(args['save_dir'], f'model_last_bin.pt'))\n",
    "        \n",
    "        # Aggiungi i risultati alle metriche\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        metrics.add_row([\n",
    "            epoch+1, \n",
    "            lr, \n",
    "            train_loss_multi, \n",
    "            train_loss_binaria, \n",
    "            train_acc, \n",
    "            train_acc_bin, \n",
    "            val_loss_multi,\n",
    "            val_loss_binaria,\n",
    "            val_acc_multi,\n",
    "            val_acc_bin,\n",
    "            test_loss_multi, \n",
    "            test_loss_binaria, \n",
    "            test_acc_multi, \n",
    "            test_acc_bin,\n",
    "            best_val_acc\n",
    "        ])\n",
    "        metrics.save_to_csv(os.path.join(args['save_dir'], f\"metrics_bin.csv\"))\n",
    "    \n",
    "    # Salva i grafici delle metriche di loss e accuracy\n",
    "    metrics_data = pd.read_csv(os.path.join(args['save_dir'], \"metrics_bin.csv\"))\n",
    "    plot_and_save_metrics(metrics_data, args['save_dir'])\n",
    "\n",
    "    # Salva la confusion matrix\n",
    "    class_names = ['Class_0', 'Class_1', 'Class_2', ..., 'Class_n']  # Sostituisci con i nomi delle classi\n",
    "    #plot_and_save_confusion_matrix(test_labels, test_preds, class_names, \"best_test_bin\", args['save_dir'])\n",
    "    plot_and_save_confusion_matrix(val_labels, val_preds, class_names, \"best_val_bin\", args['save_dir'])\n",
    "    \n",
    "    print(\"Training completato.\")\n",
    "\n",
    "# Esegui la funzione per il training binario usando un nuovo modello di classificazione\n",
    "run_binary_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Multiclass without class Other\n",
    "\n",
    "After loading the binary pretrained model 'model_last_bin.pt', trained using only all the datasets with binary classes, we fine-tune the model with two loss functions for binary and multi-classes clssification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Loading:/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/training/\n",
      "***Loading:/home/jovyan/shared/abulgheroni/datasets/HAM10k_duplicatiTranneNV/validation/\n",
      "***Loading:/home/jovyan/nfs/mgallazzi/datasets/HAM10k_test_Duplicati/divided/\n",
      "\n",
      "Numero di esempi nel dataset di training: 6968\n",
      "Creazione del nuovo modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 1, Loss Train Multi: 0.9929, Acc Train Multi: 0.7181, Loss Val Multi: 0.0031, Acc Val Multi: 0.8722, Loss Test Multi: 0.0049, Acc Test Multi: 0.7796\n",
      "Miglior acc test multi-classe, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 2, Loss Train Multi: 0.3501, Acc Train Multi: 0.8734, Loss Val Multi: 0.0018, Acc Val Multi: 0.9169, Loss Test Multi: 0.0044, Acc Test Multi: 0.8220\n",
      "Miglior acc test multi-classe, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 3, Loss Train Multi: 0.2101, Acc Train Multi: 0.9231, Loss Val Multi: 0.0014, Acc Val Multi: 0.9352, Loss Test Multi: 0.0046, Acc Test Multi: 0.8312\n",
      "Miglior acc test multi-classe, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 4, Loss Train Multi: 0.1549, Acc Train Multi: 0.9447, Loss Val Multi: 0.0011, Acc Val Multi: 0.9553, Loss Test Multi: 0.0047, Acc Test Multi: 0.8425\n",
      "Miglior acc test multi-classe, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 5, Loss Train Multi: 0.1187, Acc Train Multi: 0.9580, Loss Val Multi: 0.0006, Acc Val Multi: 0.9731, Loss Test Multi: 0.0048, Acc Test Multi: 0.8557\n",
      "Miglior acc test multi-classe, salvataggio del modello...\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 6, Loss Train Multi: 0.0822, Acc Train Multi: 0.9714, Loss Val Multi: 0.0005, Acc Val Multi: 0.9788, Loss Test Multi: 0.0050, Acc Test Multi: 0.8412\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 7, Loss Train Multi: 0.0681, Acc Train Multi: 0.9757, Loss Val Multi: 0.0002, Acc Val Multi: 0.9926, Loss Test Multi: 0.0057, Acc Test Multi: 0.8345\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 8, Loss Train Multi: 0.0520, Acc Train Multi: 0.9826, Loss Val Multi: 0.0005, Acc Val Multi: 0.9799, Loss Test Multi: 0.0059, Acc Test Multi: 0.8326\n",
      "Start training...\n",
      "Start validation...\n",
      "Start validation...\n",
      "Epoca 9, Loss Train Multi: 0.0565, Acc Train Multi: 0.9815, Loss Val Multi: 0.0004, Acc Val Multi: 0.9811, Loss Test Multi: 0.0060, Acc Test Multi: 0.8345\n",
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "# Funzioni di training e validazione\n",
    "def train_one_epoch_multi(model, train_loader, optimizer, device):\n",
    "    print('Start training...')\n",
    "    model.train()\n",
    "    running_loss_multi = 0.0\n",
    "    running_loss_binaria = 0.0\n",
    "    correct_multi = torch.tensor(0).to(device)\n",
    "    correct_bin = torch.tensor(0).to(device)\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels_multi, labels_bin in train_loader:\n",
    "        inputs, labels_multi = inputs.to(device), labels_multi.to(device)\n",
    "        labels_bin = labels_bin.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        multiclass_output, binary_output = model(inputs)\n",
    "\n",
    "        comb_loss = 0\n",
    "        # Loss multi-classe\n",
    "        if train_loader.dataset.multiclass:\n",
    "            loss_multi = criterion_multi(multiclass_output, labels_multi)\n",
    "            comb_loss += args[\"lambda_multi\"] * loss_multi \n",
    "\n",
    "        # Loss binaria\n",
    "        if train_loader.dataset.binary:\n",
    "            loss_binaria = criterion_binaria(binary_output, labels_bin)\n",
    "            comb_loss += args[\"lambda_bin\"] * loss_binaria\n",
    "\n",
    "        comb_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        if train_loader.dataset.multiclass:\n",
    "            running_loss_multi += loss_multi.item()\n",
    "            _, predicted_multi = torch.max(multiclass_output, dim=1)\n",
    "            correct_multi += (predicted_multi.view(labels_multi.size()).data == labels_multi.data).sum()\n",
    "\n",
    "        if train_loader.dataset.binary:\n",
    "            running_loss_binaria += loss_binaria.item()\n",
    "            _, predicted_bin = torch.max(binary_output, dim=1)\n",
    "            correct_bin += (predicted_bin.view(labels_bin.size()).data == labels_bin.data).sum()\n",
    "\n",
    "        total += labels_multi.size(0)\n",
    "\n",
    "    train_loss_multi = running_loss_multi / len(train_loader)\n",
    "    train_loss_binaria = running_loss_binaria / len(train_loader)\n",
    "    train_acc_multi = correct_multi / total\n",
    "    train_acc_bin = correct_bin / total\n",
    "    return train_loss_multi, train_loss_binaria, train_acc_multi, train_acc_bin\n",
    "\n",
    "def validate_multi(model, val_loader, device):\n",
    "    print('Start validation...')\n",
    "    model.eval()\n",
    "    running_loss_multi = 0.0\n",
    "    running_loss_binaria = 0.0\n",
    "    correct_multi = torch.tensor(0).to(device)\n",
    "    correct_bin = torch.tensor(0).to(device)\n",
    "    total_multi = 0\n",
    "    total_bin = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels_multi, labels_bin in val_loader:\n",
    "            inputs, labels_multi = inputs.to(device), labels_multi.to(device)\n",
    "            labels_bin = labels_bin.to(device)\n",
    "\n",
    "            multiclass_output, binary_output = model(inputs)\n",
    "\n",
    "            # Loss multi-classe\n",
    "            if val_loader.dataset.multiclass:\n",
    "                loss_multi = criterion_multi(multiclass_output, labels_multi)\n",
    "                running_loss_multi += loss_multi.item()\n",
    "                _, predicted_multi = torch.max(multiclass_output, dim=1)\n",
    "                correct_multi += (predicted_multi.view(labels_multi.size()).data == labels_multi.data).sum()\n",
    "                total_multi += labels_multi.size(0)\n",
    "                all_labels.extend(labels_multi.cpu().numpy())\n",
    "                all_predictions.extend(predicted_multi.cpu().numpy())\n",
    "\n",
    "            # Loss binaria\n",
    "            if val_loader.dataset.binary:\n",
    "                loss_binaria = criterion_binaria(binary_output, labels_bin)\n",
    "                running_loss_binaria += loss_binaria.item()\n",
    "                _, predicted_bin = torch.max(binary_output, dim=1)\n",
    "                correct_bin += (predicted_bin.view(labels_bin.size()).data == labels_bin.data).sum()\n",
    "                total_bin += labels_bin.size(0)\n",
    "\n",
    "    val_loss_multi = running_loss_multi / total_multi if total_multi > 0 else 0\n",
    "    val_loss_binaria = running_loss_binaria / total_bin if total_bin > 0 else 0\n",
    "\n",
    "    val_acc_multi_filtered = correct_multi / total_multi if total_multi > 0 else 0\n",
    "    val_acc_bin = correct_bin / total_bin if total_bin > 0 else 0\n",
    "\n",
    "    # Calcola la matrice di confusione\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    return val_loss_multi, val_loss_binaria, val_acc_multi_filtered, val_acc_bin, conf_matrix\n",
    "\n",
    "def to_cpu(x):\n",
    "    # Controlla se √® un tensore e se s√¨ lo sposta sulla CPU e ottiene il valore scalare\n",
    "    return x.cpu().item() if isinstance(x, torch.Tensor) else x\n",
    "\n",
    "def run_multiclass_training():\n",
    "    # Utilizza i dataset di classificazione definiti in args per multi-classe\n",
    "    train_dataset = BinaryImageFolder(\n",
    "        args['train_dir_class'], transform=train_transforms, binary=False, multi=True)\n",
    "    \n",
    "    val_dataset = BinaryImageFolder(\n",
    "        args['val_dir_class'], transform=val_transforms, binary=False, multi=True)\n",
    "    \n",
    "    test_dataset = BinaryImageFolder(\n",
    "        args['test_dir_class'], transform=test_transforms, binary=False, multi=True)\n",
    "    \n",
    "    # Creazione dei DataLoader per training, validazione e test\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=8)\n",
    "\n",
    "    # Stampa il numero di esempi nel dataset di training\n",
    "    print(\"\\nNumero di esempi nel dataset di training:\", len(train_dataset))\n",
    "\n",
    "    # Inizializza le metriche\n",
    "    metrics = Metrics([\"epoch\", \"lr\", \n",
    "                       \"train_loss_mult\", \"train_loss_bin\", \n",
    "                       \"train_acc_multi\", \"train_acc_bin\", \n",
    "                       \"val_loss_multi\", \"val_loss_bin\", \n",
    "                       \"val_acc_multi\", \"val_acc_bin\",\n",
    "                       \"test_loss_multi\", \"test_loss_bin\",\n",
    "                       \"test_acc_multi\", \"test_acc_bin\",\n",
    "                       \"best_val_acc\", \"conf_matrix\"])\n",
    "\n",
    "    print(\"Creazione del nuovo modello...\")\n",
    "    model = SwinClassification(num_classes_multiclass=args['num_classes'], \n",
    "                               num_classes_binary=2)\n",
    "\n",
    "    # Caricamento del modello pre-addestrato (binario)\n",
    "    model_path = os.path.join(args['save_dir'], 'model_best_test_bin.pt')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=args['device']))\n",
    "\n",
    "    model = model.to(args['device'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    lambda_lr = lambda epoch: 0.95 ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(100):  # Imposta il numero di epoche\n",
    "        # Fase di training (multi-classe)\n",
    "        train_loss_multi, train_loss_binaria, train_acc_multi, train_acc_bin = train_one_epoch_multi(\n",
    "            model, train_loader, optimizer, args['device'])\n",
    "        \n",
    "        # Fase di validazione (multi-classe)\n",
    "        val_loss_multi, val_loss_binaria, val_acc_multi, val_acc_bin, val_conf_matrix = validate_multi(\n",
    "            model, val_loader, args['device'])\n",
    "\n",
    "        # Fase di test (multi-classe)\n",
    "        test_loss_multi, test_loss_binaria, test_acc_multi, test_acc_bin, test_conf_matrix = validate_multi(\n",
    "            model, test_loader, args['device'])\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Output dei risultati\n",
    "        print(f'Epoca {epoch+1}, Loss Train Multi: {train_loss_multi:.4f}, '\n",
    "              f'Acc Train Multi: {to_cpu(train_acc_multi):.4f}, Loss Val Multi: {val_loss_multi:.4f}, '\n",
    "              f'Acc Val Multi: {to_cpu(val_acc_multi):.4f}, Loss Test Multi: {test_loss_multi:.4f}, '\n",
    "              f'Acc Test Multi: {to_cpu(test_acc_multi):.4f}')\n",
    "        \n",
    "        # Salva il modello se l'accuratezza di test multi-classe √® migliorata\n",
    "        if test_acc_multi > best_val_acc:\n",
    "            print(\"Miglior acc test multi-classe, salvataggio del modello...\")\n",
    "            best_val_acc = to_cpu(test_acc_multi)\n",
    "            torch.save(model.state_dict(), os.path.join(args['save_dir'], f'model_best_test_bin+multi2.pt'))\n",
    "        torch.save(model.state_dict(), os.path.join(args['save_dir'], f'model_last_bin+multi2.pt'))\n",
    "\n",
    "        # Aggiorna le metriche\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        metrics.add_row([\n",
    "            epoch+1, \n",
    "            lr, \n",
    "            train_loss_multi, \n",
    "            train_loss_binaria, \n",
    "            to_cpu(train_acc_multi),   # Conversione con funzione helper\n",
    "            to_cpu(train_acc_bin),     # Conversione con funzione helper\n",
    "            val_loss_multi,\n",
    "            val_loss_binaria,\n",
    "            to_cpu(val_acc_multi),     # Conversione con funzione helper\n",
    "            to_cpu(val_acc_bin),       # Conversione con funzione helper\n",
    "            test_loss_multi, \n",
    "            test_loss_binaria, \n",
    "            to_cpu(test_acc_multi),    # Conversione con funzione helper\n",
    "            to_cpu(test_acc_bin),      # Conversione con funzione helper\n",
    "            best_val_acc,\n",
    "            f\"{test_conf_matrix}\",\n",
    "        ])\n",
    "        metrics.save_to_csv(os.path.join(args['save_dir'], f\"metrics_bin+multi2.csv\"))\n",
    "    \n",
    "    print(\"Training completato.\")\n",
    "\n",
    "# Esegui la funzione per il training multi-classe\n",
    "run_multiclass_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred, target, threshold=0.5):\n",
    "    pred = pred > threshold\n",
    "    target = target > threshold\n",
    "\n",
    "    intersection = (pred & target).float().sum((1, 2))\n",
    "    union = (pred | target).float().sum((1, 2))\n",
    "\n",
    "    iou_score = (intersection + 1e-6) / (union + 1e-6) \n",
    "    return iou_score.mean().item()\n",
    "\n",
    "\n",
    "def dice_coeff(pred, target, threshold=0.5):\n",
    "    pred = pred > threshold\n",
    "    target = target > threshold\n",
    "\n",
    "    intersection = (pred & target).float().sum((1, 2))\n",
    "    total = pred.float().sum((1, 2)) + target.float().sum((1, 2))\n",
    "\n",
    "    dice_score = (2.0 * intersection + 1e-6) / (total + 1e-6)\n",
    "    return dice_score.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seg_model(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    iou_score = 0.0\n",
    "    dice_score = 0.0\n",
    "\n",
    "    for images, masks in dataloader:\n",
    "        images = images.to(args['device'])\n",
    "        masks = masks.to(args['device'])\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass e ottimizzazione\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        iou_score += iou(outputs, masks) * images.size(0)\n",
    "        dice_score += dice_coeff(outputs, masks) * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    iou_score = iou_score / len(dataloader.dataset)\n",
    "    dice_score = dice_score / len(dataloader.dataset)\n",
    "    return epoch_loss, iou_score, dice_score\n",
    "\n",
    "\n",
    "def validate_seg_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    iou_score = 0.0\n",
    "    dice_score = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(args['device'])\n",
    "            masks = masks.to(args['device'])\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            iou_score += iou(outputs, masks) * images.size(0)\n",
    "            dice_score += dice_coeff(outputs, masks) * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    iou_score = iou_score / len(dataloader.dataset)\n",
    "    dice_score = dice_score / len(dataloader.dataset)\n",
    "    return epoch_loss, iou_score, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_loss(metrics, save_dir):\n",
    "    # Estrai le loss\n",
    "    epochs = metrics['epoch']\n",
    "    train_loss = metrics['train_loss']\n",
    "    val_loss = metrics['val_loss']\n",
    "    test_loss = metrics['test_loss']\n",
    "\n",
    "    # Plot delle loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, label='Val Loss')\n",
    "    plt.plot(epochs, test_loss, label='Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Salva il grafico\n",
    "    loss_plot_path = os.path.join(save_dir, 'loss_plot_segmentation.png')\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plot delle loss salvato in: {loss_plot_path}\")\n",
    "\n",
    "\n",
    "def plot_and_save_accuracy(metrics, save_dir):\n",
    "    # Estrai IoU e Dice\n",
    "    epochs = metrics['epoch']\n",
    "    train_iou = metrics['train_iou']\n",
    "    val_iou = metrics['val_iou']\n",
    "    test_iou = metrics['test_iou']\n",
    "    \n",
    "    train_dice = metrics['train_dice']\n",
    "    val_dice = metrics['val_dice']\n",
    "    test_dice = metrics['test_dice']\n",
    "\n",
    "    # Plot di IoU\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_iou, label='Train IoU')\n",
    "    plt.plot(epochs, val_iou, label='Val IoU')\n",
    "    plt.plot(epochs, test_iou, label='Test IoU')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.title('IoU over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Salva il grafico di IoU\n",
    "    iou_plot_path = os.path.join(save_dir, 'iou_plot_segmentation.png')\n",
    "    plt.savefig(iou_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plot di IoU salvato in: {iou_plot_path}\")\n",
    "\n",
    "    # Plot di Dice coefficient\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_dice, label='Train Dice')\n",
    "    plt.plot(epochs, val_dice, label='Val Dice')\n",
    "    plt.plot(epochs, test_dice, label='Test Dice')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Dice Coefficient')\n",
    "    plt.title('Dice Coefficient over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Salva il grafico di Dice coefficient\n",
    "    dice_plot_path = os.path.join(save_dir, 'dice_plot_segmentation.png')\n",
    "    plt.savefig(dice_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plot di Dice salvato in: {dice_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model...\n",
      "Loading pre-trained: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_bin+multi2.pt\n",
      "Epoch 1/100, Train Loss: 0.4621, Train IoU: 0.7402, Train Dice: 0.7915, Val Loss: 0.3362, Val IoU: 0.8699, Val Dice: 0.9023, Test Loss: 0.3698, Test IoU: 0.8258, Test Dice: 0.8669\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Test IoU migliorata a 0.8258, salvataggio del modello migliore.\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_iou.pt\n",
      "Epoch 2/100, Train Loss: 0.3062, Train IoU: 0.8804, Train Dice: 0.9103, Val Loss: 0.2840, Val IoU: 0.8943, Val Dice: 0.9219, Test Loss: 0.3327, Test IoU: 0.8322, Test Dice: 0.8732\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Test IoU migliorata a 0.8322, salvataggio del modello migliore.\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_iou.pt\n",
      "Epoch 3/100, Train Loss: 0.2742, Train IoU: 0.8914, Train Dice: 0.9189, Val Loss: 0.2629, Val IoU: 0.8981, Val Dice: 0.9250, Test Loss: 0.3230, Test IoU: 0.8318, Test Dice: 0.8731\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 4/100, Train Loss: 0.2528, Train IoU: 0.8981, Train Dice: 0.9244, Val Loss: 0.2419, Val IoU: 0.8980, Val Dice: 0.9243, Test Loss: 0.2960, Test IoU: 0.8393, Test Dice: 0.8779\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Test IoU migliorata a 0.8393, salvataggio del modello migliore.\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_iou.pt\n",
      "Epoch 5/100, Train Loss: 0.2352, Train IoU: 0.9038, Train Dice: 0.9293, Val Loss: 0.2272, Val IoU: 0.9070, Val Dice: 0.9321, Test Loss: 0.2960, Test IoU: 0.8370, Test Dice: 0.8768\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 6/100, Train Loss: 0.2211, Train IoU: 0.9054, Train Dice: 0.9305, Val Loss: 0.2113, Val IoU: 0.9011, Val Dice: 0.9267, Test Loss: 0.2638, Test IoU: 0.8554, Test Dice: 0.8910\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Test IoU migliorata a 0.8554, salvataggio del modello migliore.\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_iou.pt\n",
      "Epoch 7/100, Train Loss: 0.2074, Train IoU: 0.9090, Train Dice: 0.9335, Val Loss: 0.2013, Val IoU: 0.9064, Val Dice: 0.9309, Test Loss: 0.2624, Test IoU: 0.8509, Test Dice: 0.8869\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 8/100, Train Loss: 0.1957, Train IoU: 0.9106, Train Dice: 0.9346, Val Loss: 0.1911, Val IoU: 0.8947, Val Dice: 0.9216, Test Loss: 0.2394, Test IoU: 0.8658, Test Dice: 0.8988\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Test IoU migliorata a 0.8658, salvataggio del modello migliore.\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_best_test_iou.pt\n",
      "Epoch 9/100, Train Loss: 0.1861, Train IoU: 0.9091, Train Dice: 0.9335, Val Loss: 0.1802, Val IoU: 0.9051, Val Dice: 0.9296, Test Loss: 0.2509, Test IoU: 0.8553, Test Dice: 0.8912\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 10/100, Train Loss: 0.1764, Train IoU: 0.9105, Train Dice: 0.9344, Val Loss: 0.1740, Val IoU: 0.9092, Val Dice: 0.9330, Test Loss: 0.2481, Test IoU: 0.8503, Test Dice: 0.8871\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 11/100, Train Loss: 0.1680, Train IoU: 0.9112, Train Dice: 0.9350, Val Loss: 0.1655, Val IoU: 0.9065, Val Dice: 0.9310, Test Loss: 0.2389, Test IoU: 0.8555, Test Dice: 0.8914\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 12/100, Train Loss: 0.1594, Train IoU: 0.9134, Train Dice: 0.9367, Val Loss: 0.1610, Val IoU: 0.9068, Val Dice: 0.9305, Test Loss: 0.2386, Test IoU: 0.8474, Test Dice: 0.8844\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 13/100, Train Loss: 0.1538, Train IoU: 0.9117, Train Dice: 0.9353, Val Loss: 0.1610, Val IoU: 0.9111, Val Dice: 0.9353, Test Loss: 0.2545, Test IoU: 0.8357, Test Dice: 0.8757\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 14/100, Train Loss: 0.1461, Train IoU: 0.9131, Train Dice: 0.9367, Val Loss: 0.1459, Val IoU: 0.9125, Val Dice: 0.9357, Test Loss: 0.2344, Test IoU: 0.8476, Test Dice: 0.8851\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 15/100, Train Loss: 0.1390, Train IoU: 0.9156, Train Dice: 0.9384, Val Loss: 0.1488, Val IoU: 0.9123, Val Dice: 0.9361, Test Loss: 0.2423, Test IoU: 0.8343, Test Dice: 0.8741\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 16/100, Train Loss: 0.1356, Train IoU: 0.9133, Train Dice: 0.9365, Val Loss: 0.1364, Val IoU: 0.9084, Val Dice: 0.9322, Test Loss: 0.2168, Test IoU: 0.8518, Test Dice: 0.8880\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 17/100, Train Loss: 0.1277, Train IoU: 0.9167, Train Dice: 0.9393, Val Loss: 0.1305, Val IoU: 0.9039, Val Dice: 0.9289, Test Loss: 0.2014, Test IoU: 0.8602, Test Dice: 0.8940\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 18/100, Train Loss: 0.1215, Train IoU: 0.9187, Train Dice: 0.9410, Val Loss: 0.1283, Val IoU: 0.9027, Val Dice: 0.9278, Test Loss: 0.2031, Test IoU: 0.8590, Test Dice: 0.8932\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 19/100, Train Loss: 0.1168, Train IoU: 0.9195, Train Dice: 0.9416, Val Loss: 0.1258, Val IoU: 0.9139, Val Dice: 0.9367, Test Loss: 0.2165, Test IoU: 0.8498, Test Dice: 0.8859\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 20/100, Train Loss: 0.1122, Train IoU: 0.9197, Train Dice: 0.9419, Val Loss: 0.1204, Val IoU: 0.9113, Val Dice: 0.9347, Test Loss: 0.2097, Test IoU: 0.8518, Test Dice: 0.8884\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 21/100, Train Loss: 0.1087, Train IoU: 0.9211, Train Dice: 0.9429, Val Loss: 0.1177, Val IoU: 0.9048, Val Dice: 0.9293, Test Loss: 0.1904, Test IoU: 0.8617, Test Dice: 0.8961\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 22/100, Train Loss: 0.1048, Train IoU: 0.9210, Train Dice: 0.9428, Val Loss: 0.1149, Val IoU: 0.9123, Val Dice: 0.9355, Test Loss: 0.2096, Test IoU: 0.8536, Test Dice: 0.8897\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 23/100, Train Loss: 0.1004, Train IoU: 0.9229, Train Dice: 0.9443, Val Loss: 0.1121, Val IoU: 0.9145, Val Dice: 0.9371, Test Loss: 0.2101, Test IoU: 0.8482, Test Dice: 0.8853\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 24/100, Train Loss: 0.0991, Train IoU: 0.9201, Train Dice: 0.9422, Val Loss: 0.1111, Val IoU: 0.9138, Val Dice: 0.9367, Test Loss: 0.2146, Test IoU: 0.8456, Test Dice: 0.8824\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 25/100, Train Loss: 0.0940, Train IoU: 0.9232, Train Dice: 0.9445, Val Loss: 0.1067, Val IoU: 0.9145, Val Dice: 0.9373, Test Loss: 0.2053, Test IoU: 0.8525, Test Dice: 0.8885\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 26/100, Train Loss: 0.0907, Train IoU: 0.9243, Train Dice: 0.9454, Val Loss: 0.1059, Val IoU: 0.9169, Val Dice: 0.9394, Test Loss: 0.2153, Test IoU: 0.8467, Test Dice: 0.8837\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 27/100, Train Loss: 0.0888, Train IoU: 0.9235, Train Dice: 0.9448, Val Loss: 0.1043, Val IoU: 0.9149, Val Dice: 0.9378, Test Loss: 0.2046, Test IoU: 0.8451, Test Dice: 0.8824\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 28/100, Train Loss: 0.0863, Train IoU: 0.9241, Train Dice: 0.9453, Val Loss: 0.1094, Val IoU: 0.9151, Val Dice: 0.9386, Test Loss: 0.2308, Test IoU: 0.8341, Test Dice: 0.8745\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 29/100, Train Loss: 0.0851, Train IoU: 0.9230, Train Dice: 0.9444, Val Loss: 0.0988, Val IoU: 0.9103, Val Dice: 0.9334, Test Loss: 0.1930, Test IoU: 0.8543, Test Dice: 0.8903\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 30/100, Train Loss: 0.0819, Train IoU: 0.9252, Train Dice: 0.9461, Val Loss: 0.1013, Val IoU: 0.9075, Val Dice: 0.9313, Test Loss: 0.1875, Test IoU: 0.8564, Test Dice: 0.8913\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 31/100, Train Loss: 0.0808, Train IoU: 0.9241, Train Dice: 0.9452, Val Loss: 0.0968, Val IoU: 0.9093, Val Dice: 0.9329, Test Loss: 0.1973, Test IoU: 0.8570, Test Dice: 0.8924\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 32/100, Train Loss: 0.0781, Train IoU: 0.9257, Train Dice: 0.9465, Val Loss: 0.0988, Val IoU: 0.9059, Val Dice: 0.9310, Test Loss: 0.1916, Test IoU: 0.8587, Test Dice: 0.8926\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 33/100, Train Loss: 0.0766, Train IoU: 0.9250, Train Dice: 0.9460, Val Loss: 0.0985, Val IoU: 0.9154, Val Dice: 0.9386, Test Loss: 0.2149, Test IoU: 0.8375, Test Dice: 0.8771\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 34/100, Train Loss: 0.0747, Train IoU: 0.9256, Train Dice: 0.9465, Val Loss: 0.0927, Val IoU: 0.9127, Val Dice: 0.9355, Test Loss: 0.2013, Test IoU: 0.8515, Test Dice: 0.8874\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 35/100, Train Loss: 0.0716, Train IoU: 0.9273, Train Dice: 0.9476, Val Loss: 0.0897, Val IoU: 0.9163, Val Dice: 0.9383, Test Loss: 0.1968, Test IoU: 0.8486, Test Dice: 0.8858\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 36/100, Train Loss: 0.0702, Train IoU: 0.9285, Train Dice: 0.9487, Val Loss: 0.0930, Val IoU: 0.9102, Val Dice: 0.9334, Test Loss: 0.1980, Test IoU: 0.8543, Test Dice: 0.8901\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 37/100, Train Loss: 0.0689, Train IoU: 0.9283, Train Dice: 0.9485, Val Loss: 0.0925, Val IoU: 0.9095, Val Dice: 0.9327, Test Loss: 0.1995, Test IoU: 0.8532, Test Dice: 0.8888\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 38/100, Train Loss: 0.0674, Train IoU: 0.9283, Train Dice: 0.9486, Val Loss: 0.0909, Val IoU: 0.9175, Val Dice: 0.9396, Test Loss: 0.2127, Test IoU: 0.8454, Test Dice: 0.8831\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 39/100, Train Loss: 0.0661, Train IoU: 0.9292, Train Dice: 0.9492, Val Loss: 0.0911, Val IoU: 0.9159, Val Dice: 0.9383, Test Loss: 0.2272, Test IoU: 0.8367, Test Dice: 0.8749\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 40/100, Train Loss: 0.0665, Train IoU: 0.9271, Train Dice: 0.9477, Val Loss: 0.0887, Val IoU: 0.9064, Val Dice: 0.9306, Test Loss: 0.1841, Test IoU: 0.8570, Test Dice: 0.8909\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 41/100, Train Loss: 0.0641, Train IoU: 0.9292, Train Dice: 0.9493, Val Loss: 0.0837, Val IoU: 0.9129, Val Dice: 0.9360, Test Loss: 0.1924, Test IoU: 0.8530, Test Dice: 0.8884\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 42/100, Train Loss: 0.0617, Train IoU: 0.9308, Train Dice: 0.9504, Val Loss: 0.0868, Val IoU: 0.9169, Val Dice: 0.9391, Test Loss: 0.2053, Test IoU: 0.8482, Test Dice: 0.8851\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 43/100, Train Loss: 0.0606, Train IoU: 0.9316, Train Dice: 0.9512, Val Loss: 0.0850, Val IoU: 0.9140, Val Dice: 0.9368, Test Loss: 0.1931, Test IoU: 0.8574, Test Dice: 0.8923\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 44/100, Train Loss: 0.0601, Train IoU: 0.9305, Train Dice: 0.9503, Val Loss: 0.0836, Val IoU: 0.9174, Val Dice: 0.9394, Test Loss: 0.2048, Test IoU: 0.8469, Test Dice: 0.8838\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 45/100, Train Loss: 0.0592, Train IoU: 0.9311, Train Dice: 0.9509, Val Loss: 0.0862, Val IoU: 0.9157, Val Dice: 0.9380, Test Loss: 0.2133, Test IoU: 0.8480, Test Dice: 0.8843\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 46/100, Train Loss: 0.0572, Train IoU: 0.9326, Train Dice: 0.9519, Val Loss: 0.0819, Val IoU: 0.9150, Val Dice: 0.9375, Test Loss: 0.1971, Test IoU: 0.8518, Test Dice: 0.8879\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 47/100, Train Loss: 0.0562, Train IoU: 0.9334, Train Dice: 0.9526, Val Loss: 0.0826, Val IoU: 0.9180, Val Dice: 0.9398, Test Loss: 0.2073, Test IoU: 0.8462, Test Dice: 0.8835\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 48/100, Train Loss: 0.0551, Train IoU: 0.9337, Train Dice: 0.9528, Val Loss: 0.0834, Val IoU: 0.9171, Val Dice: 0.9391, Test Loss: 0.2062, Test IoU: 0.8517, Test Dice: 0.8881\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 49/100, Train Loss: 0.0559, Train IoU: 0.9321, Train Dice: 0.9515, Val Loss: 0.0835, Val IoU: 0.9125, Val Dice: 0.9355, Test Loss: 0.2022, Test IoU: 0.8531, Test Dice: 0.8886\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 50/100, Train Loss: 0.0541, Train IoU: 0.9335, Train Dice: 0.9527, Val Loss: 0.0842, Val IoU: 0.9171, Val Dice: 0.9390, Test Loss: 0.2158, Test IoU: 0.8475, Test Dice: 0.8837\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 51/100, Train Loss: 0.0529, Train IoU: 0.9341, Train Dice: 0.9530, Val Loss: 0.0854, Val IoU: 0.9188, Val Dice: 0.9405, Test Loss: 0.2253, Test IoU: 0.8398, Test Dice: 0.8784\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 52/100, Train Loss: 0.0519, Train IoU: 0.9351, Train Dice: 0.9538, Val Loss: 0.0843, Val IoU: 0.9173, Val Dice: 0.9396, Test Loss: 0.2196, Test IoU: 0.8446, Test Dice: 0.8827\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 53/100, Train Loss: 0.0509, Train IoU: 0.9352, Train Dice: 0.9539, Val Loss: 0.0829, Val IoU: 0.9162, Val Dice: 0.9380, Test Loss: 0.2073, Test IoU: 0.8504, Test Dice: 0.8864\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 54/100, Train Loss: 0.0496, Train IoU: 0.9365, Train Dice: 0.9550, Val Loss: 0.0818, Val IoU: 0.9152, Val Dice: 0.9377, Test Loss: 0.2092, Test IoU: 0.8508, Test Dice: 0.8870\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 55/100, Train Loss: 0.0491, Train IoU: 0.9365, Train Dice: 0.9549, Val Loss: 0.0831, Val IoU: 0.9164, Val Dice: 0.9383, Test Loss: 0.2038, Test IoU: 0.8531, Test Dice: 0.8888\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 56/100, Train Loss: 0.0498, Train IoU: 0.9352, Train Dice: 0.9539, Val Loss: 0.0824, Val IoU: 0.9072, Val Dice: 0.9309, Test Loss: 0.1877, Test IoU: 0.8583, Test Dice: 0.8930\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 57/100, Train Loss: 0.0501, Train IoU: 0.9343, Train Dice: 0.9533, Val Loss: 0.0801, Val IoU: 0.9191, Val Dice: 0.9409, Test Loss: 0.2184, Test IoU: 0.8452, Test Dice: 0.8825\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 58/100, Train Loss: 0.0480, Train IoU: 0.9360, Train Dice: 0.9545, Val Loss: 0.0831, Val IoU: 0.9176, Val Dice: 0.9393, Test Loss: 0.2199, Test IoU: 0.8472, Test Dice: 0.8839\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 59/100, Train Loss: 0.0471, Train IoU: 0.9372, Train Dice: 0.9554, Val Loss: 0.0819, Val IoU: 0.9167, Val Dice: 0.9387, Test Loss: 0.2140, Test IoU: 0.8521, Test Dice: 0.8887\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 60/100, Train Loss: 0.0461, Train IoU: 0.9378, Train Dice: 0.9559, Val Loss: 0.0822, Val IoU: 0.9174, Val Dice: 0.9395, Test Loss: 0.2140, Test IoU: 0.8500, Test Dice: 0.8865\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 61/100, Train Loss: 0.0458, Train IoU: 0.9376, Train Dice: 0.9558, Val Loss: 0.0821, Val IoU: 0.9178, Val Dice: 0.9394, Test Loss: 0.2265, Test IoU: 0.8445, Test Dice: 0.8816\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 62/100, Train Loss: 0.0456, Train IoU: 0.9376, Train Dice: 0.9557, Val Loss: 0.0814, Val IoU: 0.9182, Val Dice: 0.9400, Test Loss: 0.2270, Test IoU: 0.8449, Test Dice: 0.8822\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 63/100, Train Loss: 0.0452, Train IoU: 0.9378, Train Dice: 0.9559, Val Loss: 0.0807, Val IoU: 0.9189, Val Dice: 0.9407, Test Loss: 0.2225, Test IoU: 0.8458, Test Dice: 0.8834\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 64/100, Train Loss: 0.0448, Train IoU: 0.9378, Train Dice: 0.9560, Val Loss: 0.0811, Val IoU: 0.9140, Val Dice: 0.9367, Test Loss: 0.2083, Test IoU: 0.8503, Test Dice: 0.8863\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 65/100, Train Loss: 0.0452, Train IoU: 0.9369, Train Dice: 0.9552, Val Loss: 0.0822, Val IoU: 0.9138, Val Dice: 0.9367, Test Loss: 0.2170, Test IoU: 0.8502, Test Dice: 0.8858\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 66/100, Train Loss: 0.0431, Train IoU: 0.9396, Train Dice: 0.9573, Val Loss: 0.0809, Val IoU: 0.9156, Val Dice: 0.9377, Test Loss: 0.2166, Test IoU: 0.8509, Test Dice: 0.8878\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 67/100, Train Loss: 0.0444, Train IoU: 0.9384, Train Dice: 0.9564, Val Loss: 0.0789, Val IoU: 0.9140, Val Dice: 0.9366, Test Loss: 0.2077, Test IoU: 0.8513, Test Dice: 0.8871\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 68/100, Train Loss: 0.0443, Train IoU: 0.9372, Train Dice: 0.9554, Val Loss: 0.0791, Val IoU: 0.9133, Val Dice: 0.9358, Test Loss: 0.2099, Test IoU: 0.8513, Test Dice: 0.8874\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 69/100, Train Loss: 0.0436, Train IoU: 0.9384, Train Dice: 0.9563, Val Loss: 0.0844, Val IoU: 0.9127, Val Dice: 0.9352, Test Loss: 0.2115, Test IoU: 0.8455, Test Dice: 0.8820\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 70/100, Train Loss: 0.0534, Train IoU: 0.9279, Train Dice: 0.9480, Val Loss: 0.0788, Val IoU: 0.9107, Val Dice: 0.9338, Test Loss: 0.2107, Test IoU: 0.8490, Test Dice: 0.8849\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 71/100, Train Loss: 0.0455, Train IoU: 0.9356, Train Dice: 0.9542, Val Loss: 0.0819, Val IoU: 0.9159, Val Dice: 0.9383, Test Loss: 0.2159, Test IoU: 0.8453, Test Dice: 0.8823\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 72/100, Train Loss: 0.0426, Train IoU: 0.9384, Train Dice: 0.9564, Val Loss: 0.0808, Val IoU: 0.9166, Val Dice: 0.9386, Test Loss: 0.2343, Test IoU: 0.8460, Test Dice: 0.8830\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 73/100, Train Loss: 0.0414, Train IoU: 0.9398, Train Dice: 0.9574, Val Loss: 0.0829, Val IoU: 0.9159, Val Dice: 0.9379, Test Loss: 0.2321, Test IoU: 0.8467, Test Dice: 0.8838\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 74/100, Train Loss: 0.0408, Train IoU: 0.9400, Train Dice: 0.9576, Val Loss: 0.0833, Val IoU: 0.9180, Val Dice: 0.9397, Test Loss: 0.2356, Test IoU: 0.8429, Test Dice: 0.8807\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 75/100, Train Loss: 0.0403, Train IoU: 0.9405, Train Dice: 0.9580, Val Loss: 0.0827, Val IoU: 0.9166, Val Dice: 0.9387, Test Loss: 0.2283, Test IoU: 0.8453, Test Dice: 0.8813\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 76/100, Train Loss: 0.0394, Train IoU: 0.9415, Train Dice: 0.9587, Val Loss: 0.0820, Val IoU: 0.9161, Val Dice: 0.9383, Test Loss: 0.2227, Test IoU: 0.8507, Test Dice: 0.8871\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 77/100, Train Loss: 0.0410, Train IoU: 0.9398, Train Dice: 0.9574, Val Loss: 0.0849, Val IoU: 0.9173, Val Dice: 0.9395, Test Loss: 0.2389, Test IoU: 0.8398, Test Dice: 0.8774\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 78/100, Train Loss: 0.0400, Train IoU: 0.9405, Train Dice: 0.9580, Val Loss: 0.0848, Val IoU: 0.9161, Val Dice: 0.9384, Test Loss: 0.2178, Test IoU: 0.8502, Test Dice: 0.8870\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 79/100, Train Loss: 0.0415, Train IoU: 0.9384, Train Dice: 0.9564, Val Loss: 0.0808, Val IoU: 0.9157, Val Dice: 0.9380, Test Loss: 0.2225, Test IoU: 0.8462, Test Dice: 0.8827\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 80/100, Train Loss: 0.0390, Train IoU: 0.9410, Train Dice: 0.9584, Val Loss: 0.0845, Val IoU: 0.9150, Val Dice: 0.9375, Test Loss: 0.2242, Test IoU: 0.8498, Test Dice: 0.8859\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 81/100, Train Loss: 0.0413, Train IoU: 0.9393, Train Dice: 0.9571, Val Loss: 0.0882, Val IoU: 0.9020, Val Dice: 0.9278, Test Loss: 0.1941, Test IoU: 0.8559, Test Dice: 0.8897\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 82/100, Train Loss: 0.0520, Train IoU: 0.9278, Train Dice: 0.9482, Val Loss: 0.0789, Val IoU: 0.9144, Val Dice: 0.9370, Test Loss: 0.2223, Test IoU: 0.8412, Test Dice: 0.8790\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 83/100, Train Loss: 0.0417, Train IoU: 0.9383, Train Dice: 0.9564, Val Loss: 0.0818, Val IoU: 0.9172, Val Dice: 0.9393, Test Loss: 0.2258, Test IoU: 0.8479, Test Dice: 0.8847\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 84/100, Train Loss: 0.0391, Train IoU: 0.9408, Train Dice: 0.9582, Val Loss: 0.0815, Val IoU: 0.9145, Val Dice: 0.9369, Test Loss: 0.2220, Test IoU: 0.8529, Test Dice: 0.8886\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 85/100, Train Loss: 0.0397, Train IoU: 0.9396, Train Dice: 0.9572, Val Loss: 0.0839, Val IoU: 0.9115, Val Dice: 0.9345, Test Loss: 0.2191, Test IoU: 0.8541, Test Dice: 0.8899\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 86/100, Train Loss: 0.0384, Train IoU: 0.9409, Train Dice: 0.9583, Val Loss: 0.0823, Val IoU: 0.9160, Val Dice: 0.9382, Test Loss: 0.2371, Test IoU: 0.8488, Test Dice: 0.8852\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 87/100, Train Loss: 0.0375, Train IoU: 0.9418, Train Dice: 0.9590, Val Loss: 0.0845, Val IoU: 0.9170, Val Dice: 0.9388, Test Loss: 0.2496, Test IoU: 0.8431, Test Dice: 0.8810\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 88/100, Train Loss: 0.0367, Train IoU: 0.9428, Train Dice: 0.9598, Val Loss: 0.0853, Val IoU: 0.9130, Val Dice: 0.9361, Test Loss: 0.2286, Test IoU: 0.8513, Test Dice: 0.8872\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 89/100, Train Loss: 0.0364, Train IoU: 0.9432, Train Dice: 0.9601, Val Loss: 0.0820, Val IoU: 0.9169, Val Dice: 0.9390, Test Loss: 0.2298, Test IoU: 0.8499, Test Dice: 0.8861\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 90/100, Train Loss: 0.0371, Train IoU: 0.9419, Train Dice: 0.9591, Val Loss: 0.0850, Val IoU: 0.9153, Val Dice: 0.9375, Test Loss: 0.2404, Test IoU: 0.8436, Test Dice: 0.8814\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 91/100, Train Loss: 0.0364, Train IoU: 0.9430, Train Dice: 0.9599, Val Loss: 0.0844, Val IoU: 0.9144, Val Dice: 0.9369, Test Loss: 0.2290, Test IoU: 0.8532, Test Dice: 0.8886\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 92/100, Train Loss: 0.0354, Train IoU: 0.9441, Train Dice: 0.9607, Val Loss: 0.0845, Val IoU: 0.9140, Val Dice: 0.9366, Test Loss: 0.2302, Test IoU: 0.8503, Test Dice: 0.8862\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 93/100, Train Loss: 0.0348, Train IoU: 0.9446, Train Dice: 0.9611, Val Loss: 0.0836, Val IoU: 0.9182, Val Dice: 0.9401, Test Loss: 0.2376, Test IoU: 0.8487, Test Dice: 0.8855\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 94/100, Train Loss: 0.0362, Train IoU: 0.9431, Train Dice: 0.9599, Val Loss: 0.0849, Val IoU: 0.9141, Val Dice: 0.9367, Test Loss: 0.2169, Test IoU: 0.8545, Test Dice: 0.8898\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 95/100, Train Loss: 0.0358, Train IoU: 0.9434, Train Dice: 0.9602, Val Loss: 0.0832, Val IoU: 0.9169, Val Dice: 0.9390, Test Loss: 0.2435, Test IoU: 0.8508, Test Dice: 0.8870\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 96/100, Train Loss: 0.0349, Train IoU: 0.9442, Train Dice: 0.9607, Val Loss: 0.0834, Val IoU: 0.9180, Val Dice: 0.9397, Test Loss: 0.2412, Test IoU: 0.8483, Test Dice: 0.8851\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 97/100, Train Loss: 0.0340, Train IoU: 0.9452, Train Dice: 0.9615, Val Loss: 0.0854, Val IoU: 0.9147, Val Dice: 0.9369, Test Loss: 0.2257, Test IoU: 0.8543, Test Dice: 0.8901\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 98/100, Train Loss: 0.0338, Train IoU: 0.9454, Train Dice: 0.9617, Val Loss: 0.0837, Val IoU: 0.9178, Val Dice: 0.9396, Test Loss: 0.2430, Test IoU: 0.8481, Test Dice: 0.8847\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 99/100, Train Loss: 0.0335, Train IoU: 0.9456, Train Dice: 0.9618, Val Loss: 0.0868, Val IoU: 0.9158, Val Dice: 0.9379, Test Loss: 0.2502, Test IoU: 0.8482, Test Dice: 0.8845\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Epoch 100/100, Train Loss: 0.0338, Train IoU: 0.9450, Train Dice: 0.9613, Val Loss: 0.0859, Val IoU: 0.9167, Val Dice: 0.9389, Test Loss: 0.2484, Test IoU: 0.8517, Test Dice: 0.8880\n",
      "Saving model: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/model_seg_last.pt\n",
      "Training completato.\n",
      "Plot delle loss salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/loss_plot_segmentation.png\n",
      "Plot di IoU salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/iou_plot_segmentation.png\n",
      "Plot di Dice salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/dice_plot_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "def run_training_segmentation():\n",
    "    # Usa i dataloader per training, validazione e test\n",
    "    train_loader = train_segmentation_loader\n",
    "    val_loader = val_segmentation_loader\n",
    "    test_loader = test_segmentation_loader\n",
    "\n",
    "    metrics = Metrics([\"epoch\", \"lr\", \n",
    "                       \"train_loss\", \"train_iou\", \"train_dice\", \n",
    "                       \"val_loss\", \"val_iou\", \"val_dice\", \n",
    "                       \"test_loss\", \"test_iou\", \"test_dice\"])\n",
    "\n",
    "    print(\"Creating new model...\")\n",
    "    model = SwinClassification(num_classes_multiclass=args['num_classes'], \n",
    "                               num_classes_binary=2)\n",
    "\n",
    "    # Carica i pesi del modello classificazione migliore (multiclasse + binaria)\n",
    "    model_path = os.path.join(args['save_dir'], 'model_best_test_bin+multi2.pt')\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # Converti il modello in modalit√† segmentazione\n",
    "    model = model.convert_to_segmentation()  # Aggiungi questa funzione al tuo modello Swin\n",
    "\n",
    "    # Sposta il modello sulla GPU\n",
    "    model = model.to(args['device'])\n",
    "\n",
    "    # Definire la loss function e l'ottimizzatore\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Usare BCEWithLogitsLoss per output a singolo canale e multi-classe\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "    # Numero di epoche per il training\n",
    "    num_epochs = 100\n",
    "\n",
    "    # Variabile per tenere traccia della migliore IoU su test\n",
    "    best_test_iou = 0.0\n",
    "\n",
    "    # Training del modello\n",
    "    for epoch in range(num_epochs):\n",
    "        # Fase di training\n",
    "        epoch_loss, iou_score, dice_score = train_seg_model(model, train_loader, criterion, optimizer)\n",
    "        \n",
    "        # Fase di validazione\n",
    "        val_loss, val_iou, val_dice = validate_seg_model(model, val_loader, criterion)\n",
    "\n",
    "        # Fase di test\n",
    "        test_loss, test_iou, test_dice = validate_seg_model(model, test_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train IoU: {iou_score:.4f}, Train Dice: {dice_score:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}, Val Dice: {val_dice:.4f}, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test IoU: {test_iou:.4f}, Test Dice: {test_dice:.4f}\")\n",
    "\n",
    "        # Salvataggio dei risultati\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        metrics.add_row([\n",
    "            epoch+1, \n",
    "            lr, \n",
    "            epoch_loss, \n",
    "            iou_score, \n",
    "            dice_score,\n",
    "            val_loss,\n",
    "            val_iou,\n",
    "            val_dice,\n",
    "            test_loss,\n",
    "            test_iou,\n",
    "            test_dice,\n",
    "        ])\n",
    "        metrics.save_to_csv(os.path.join(args['save_dir'], \"metrics_segmentation.csv\"))\n",
    "\n",
    "        # Salvataggio del modello corrente\n",
    "        model.save_weights(os.path.join(args['save_dir'], 'model_seg_last.pt'))\n",
    "\n",
    "        # **Salva il modello se ha la migliore IoU sul test set**\n",
    "        if test_iou > best_test_iou:\n",
    "            print(f\"Test IoU migliorata a {test_iou:.4f}, salvataggio del modello migliore.\")\n",
    "            best_test_iou = test_iou\n",
    "            model.save_weights(os.path.join(args['save_dir'], 'model_best_test_iou.pt'))\n",
    "\n",
    "    print(\"Training completato.\")\n",
    "\n",
    "    # Carica le metriche dal file CSV\n",
    "    metrics_data = pd.read_csv(os.path.join(args['save_dir'], \"metrics_segmentation.csv\"))\n",
    "\n",
    "    # Salva i plot di Loss e Accuracy (IoU e Dice coefficient)\n",
    "    plot_and_save_loss(metrics_data, args['save_dir'])\n",
    "    plot_and_save_accuracy(metrics_data, args['save_dir'])\n",
    "\n",
    "# Esegui il training per la segmentazione\n",
    "run_training_segmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def test_seg():\n",
    "    seg_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Selezione casuale dell'immagine dal dataset\n",
    "    root_dir = os.path.join(args['test_dir_class'], '0.MEL/')\n",
    "    images = os.listdir(root_dir)\n",
    "    idx = random.randint(0, len(images) - 1)\n",
    "    print(\"Opening:\", images[idx])\n",
    "    img = Image.open(os.path.join(root_dir, images[idx]))\n",
    "    img_tensor = seg_transform(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # Funzione per eseguire il modello e ottenere l'output della segmentazione\n",
    "    def run_model(model_path):\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        model = SwinSeg()\n",
    "        model.load_weights(model_path)\n",
    "        model = model.to(args['device'])\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor.to(args['device']))\n",
    "        segmentation = output.squeeze().cpu().numpy()\n",
    "        return segmentation\n",
    "\n",
    "    # Funzione per ottenere il bounding box dalla segmentazione\n",
    "    def get_bounding_box(segmentation, img):\n",
    "        binary_mask = (segmentation > 0.5).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) == 0:\n",
    "            return None, None, None, None\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Scala il bounding box in base alla dimensione originale dell'immagine\n",
    "        orig_width, orig_height = img.size\n",
    "        x_scale = orig_width / 224\n",
    "        y_scale = orig_height / 224\n",
    "        x, y, w, h = int(x * x_scale), int(y * y_scale), int(w * x_scale), int(h * y_scale)\n",
    "        \n",
    "        return x, y, w, h\n",
    "\n",
    "    # Funzione per visualizzare i risultati\n",
    "    def plot_results(segmentation, img, model_name, box_color):\n",
    "        x, y, w, h = get_bounding_box(segmentation, img)\n",
    "\n",
    "        # Crea una copia dell'immagine con la bounding box\n",
    "        img_with_box = img.copy()\n",
    "        if x is not None:  # Se c'√® una bounding box valida\n",
    "            draw = ImageDraw.Draw(img_with_box)\n",
    "            draw.rectangle([x, y, x+w, y+h], outline=box_color, width=3)\n",
    "\n",
    "        # Plot dei risultati con dimensioni 15x5 per ogni immagine\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Immagine normalizzata\n",
    "        plt.subplot(1, 4, 1)\n",
    "        img_normalized = img_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        plt.imshow(img_normalized)\n",
    "        plt.title('Img Normalized')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Segmentazione\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(segmentation, cmap='gray')\n",
    "        plt.title(f'Segmentation ({model_name})')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Immagine originale\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Immagine con bounding box\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(img_with_box)\n",
    "        plt.title(f'Bounding Box ({model_name})')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Esegui il modello \"last\"\n",
    "    segmentation_last = run_model(os.path.join(args['save_dir'], 'model_seg_last.pt'))\n",
    "    plot_results(segmentation_last, img, \"last model\", \"red\")\n",
    "\n",
    "    # Esegui il modello \"best IoU\"\n",
    "    segmentation_best = run_model(os.path.join(args['save_dir'], 'model_best_test_iou.pt'))\n",
    "    plot_results(segmentation_best, img, \"best IoU model\", \"blue\")\n",
    "\n",
    "test_seg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with duplicates\n",
    "#### For having another type of validation we want to use another dataset given by the ISIC challenge 2018. The number of images of this dataset is 1511.\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per formattare i valori in percentuale\n",
    "def format_percentage(value):\n",
    "    return f\"{value * 100:.2f}\"\n",
    "\n",
    "# Funzione per calcolare Sensitivity e Specificity\n",
    "def calculate_sensitivity_specificity(y_true, y_pred):\n",
    "    TP = ((y_true == 1) & (y_pred == 1)).sum()\n",
    "    TN = ((y_true == 0) & (y_pred == 0)).sum()\n",
    "    FP = ((y_true == 0) & (y_pred == 1)).sum()\n",
    "    FN = ((y_true == 1) & (y_pred == 0)).sum()\n",
    "    \n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Funzione per plottare la confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\", save_path=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion Matrix salvata in: {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix salvata in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/Test_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** METRICHE DI CLASSIFICAZIONE ***\n",
      "                       precision   recall   f1-score   support\n",
      "\n",
      "0.MEL                   78.06     70.76       74.23      171.0\n",
      "1.NV                    90.79     95.59       93.13      908.0\n",
      "2.BCC                   76.42     87.10       81.41       93.0\n",
      "3.AKIEC                 72.09     72.09       72.09       43.0\n",
      "4.BKL                   86.26     72.35       78.70      217.0\n",
      "5.DF                    91.43     72.73       81.01       44.0\n",
      "6.VASC                  85.29     82.86       84.06       35.0\n",
      "\n",
      "accuracy                            87.29\n",
      "\n",
      "AUC Totale (Macro-Average): 0.9782\n",
      "AUC Totale (Weighted-Average): 0.9705\n",
      "\n",
      "ROC AUC per classe:\n",
      "0.MEL               0.9504\n",
      "1.NV                0.9718\n",
      "2.BCC               0.9924\n",
      "3.AKIEC             0.9897\n",
      "4.BKL               0.9601\n",
      "5.DF                0.9907\n",
      "6.VASC              0.9925\n",
      "\n",
      "Sensitivity per classe:\n",
      "0.MEL               0.7076\n",
      "1.NV                0.9559\n",
      "2.BCC               0.8710\n",
      "3.AKIEC             0.7209\n",
      "4.BKL               0.7235\n",
      "5.DF                0.7273\n",
      "6.VASC              0.8286\n",
      "\n",
      "Specificity per classe:\n",
      "0.MEL               0.9746\n",
      "1.NV                0.8541\n",
      "2.BCC               0.9824\n",
      "3.AKIEC             0.9918\n",
      "4.BKL               0.9807\n",
      "5.DF                0.9980\n",
      "6.VASC              0.9966\n",
      "\n",
      "Report salvato in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/Test_classification_report.txt\n",
      "ROC Curve per classe salvata in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/Test_roc_curve_classes.png\n",
      "Macro e Weighted ROC Curve salvata in: experiments/1.3.2.Swin_class+seg_NOconcatenazione_dataset(run_binary_training)_val+test_seg/Test_roc_curve_macro_weighted.png\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del modello per la classificazione multiclasse\n",
    "device = args[\"device\"]\n",
    "model_path = os.path.join(args['save_dir'], 'model_best_test_bin+multi2.pt')\n",
    "\n",
    "# Definisci il modello per la classificazione multiclasse\n",
    "model = SwinClassification(num_classes_multiclass=args['num_classes'], num_classes_binary=2)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Inizializza i tensori per le predizioni e le etichette vere\n",
    "predlist_test_multi = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "labels_multi_multi = torch.zeros(0, dtype=torch.long, device='cpu')\n",
    "\n",
    "# Probabilit√† per calcolo ROC e AUC\n",
    "proba_test_multi = torch.zeros(0, device='cpu')\n",
    "\n",
    "# Esegui il test senza gradiente\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels_multi, labels_bin) in enumerate(test_loader):  # Usa test_loader per la classificazione\n",
    "        inputs = inputs.to(device)\n",
    "        labels_multi = labels_multi.to(device)\n",
    "\n",
    "        # Ottieni le predizioni del modello\n",
    "        multiclass_output, _ = model(inputs)  # Prendi solo l'output multiclasse\n",
    "        preds_multi = torch.argmax(multiclass_output, dim=1)  # Predizione della classe\n",
    "        proba_test_multi = torch.cat([proba_test_multi, multiclass_output.softmax(dim=1).cpu()])\n",
    "        \n",
    "        # Append batch prediction results\n",
    "        predlist_test_multi = torch.cat([predlist_test_multi, preds_multi.view(-1).cpu()])\n",
    "        labels_multi_multi = torch.cat([labels_multi_multi, labels_multi.view(-1).cpu()])\n",
    "\n",
    "# Conversione dei tensori in numpy per l'elaborazione successiva\n",
    "predlist_test_multi = predlist_test_multi.numpy()\n",
    "labels_multi_multi = labels_multi_multi.numpy()\n",
    "proba_test_multi = proba_test_multi.numpy()\n",
    "\n",
    "# Confusion Matrix per la classificazione multiclasse\n",
    "conf_matrix = confusion_matrix(labels_multi_multi, predlist_test_multi)\n",
    "\n",
    "# Definisci i nomi delle classi per la classificazione multiclasse\n",
    "class_names = ['0.MEL', '1.NV', '2.BCC', '3.AKIEC', '4.BKL', '5.DF', '6.VASC']\n",
    "\n",
    "# Plot della confusion matrix\n",
    "cm_save_path = os.path.join(args['save_dir'], 'Test_confusion_matrix.png')\n",
    "plot_confusion_matrix(conf_matrix, class_names, save_path=cm_save_path)\n",
    "\n",
    "# Calcolo delle metriche: ROC, AUC, Sensitivity e Specificity\n",
    "roc_auc_dict = {}\n",
    "sensitivity_dict = {}\n",
    "specificity_dict = {}\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    y_true = (labels_multi_multi == i).astype(int)  # Verit√† per la classe corrente (one-vs-all)\n",
    "    y_score = proba_test_multi[:, i]  # Probabilit√† per la classe corrente\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(set(y_true)) > 1:  # Calcola solo se ci sono sia 0 che 1 nella classe\n",
    "        roc_auc_dict[class_name] = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    # Sensitivity e Specificity\n",
    "    y_pred = (predlist_test_multi == i).astype(int)\n",
    "    sensitivity, specificity = calculate_sensitivity_specificity(y_true, y_pred)\n",
    "    sensitivity_dict[class_name] = sensitivity\n",
    "    specificity_dict[class_name] = specificity\n",
    "\n",
    "# Calcolo delle AUC totali (macro e weighted)\n",
    "y_true_binarized = label_binarize(labels_multi_multi, classes=list(range(len(class_names))))  # Binarizza i target\n",
    "auc_macro = roc_auc_score(y_true_binarized, proba_test_multi, average=\"macro\", multi_class=\"ovr\")\n",
    "auc_weighted = roc_auc_score(y_true_binarized, proba_test_multi, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "# Report di classificazione\n",
    "report = classification_report(labels_multi_multi, predlist_test_multi, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Formattazione del report\n",
    "formatted_report = \"                       precision   recall   f1-score   support\\n\\n\"\n",
    "for class_name in class_names:\n",
    "    precision = format_percentage(report[class_name]['precision'])\n",
    "    recall = format_percentage(report[class_name]['recall'])\n",
    "    f1_score = format_percentage(report[class_name]['f1-score'])\n",
    "    support = report[class_name]['support']\n",
    "    formatted_report += f\"{class_name:<20}{precision:>9}    {recall:>6}    {f1_score:>8}   {support:>8}\\n\"\n",
    "\n",
    "# Aggiungi le medie, l'accuratezza e le AUC totali\n",
    "accuracy = format_percentage(report['accuracy'])\n",
    "formatted_report += f\"\\naccuracy                           {accuracy:>6}\\n\"\n",
    "formatted_report += f\"\\nAUC Totale (Macro-Average): {auc_macro:.4f}\\n\"\n",
    "formatted_report += f\"AUC Totale (Weighted-Average): {auc_weighted:.4f}\\n\"\n",
    "\n",
    "# Aggiungi ROC AUC, Sensitivity e Specificity\n",
    "formatted_report += \"\\nROC AUC per classe:\\n\"\n",
    "for class_name, auc_value in roc_auc_dict.items():\n",
    "    formatted_report += f\"{class_name:<20}{auc_value:.4f}\\n\"\n",
    "\n",
    "formatted_report += \"\\nSensitivity per classe:\\n\"\n",
    "for class_name, sensitivity in sensitivity_dict.items():\n",
    "    formatted_report += f\"{class_name:<20}{sensitivity:.4f}\\n\"\n",
    "\n",
    "formatted_report += \"\\nSpecificity per classe:\\n\"\n",
    "for class_name, specificity in specificity_dict.items():\n",
    "    formatted_report += f\"{class_name:<20}{specificity:.4f}\\n\"\n",
    "\n",
    "# Stampa diretta delle metriche\n",
    "print(\"\\n*** METRICHE DI CLASSIFICAZIONE ***\")\n",
    "print(formatted_report)\n",
    "\n",
    "# Salva il report in un file\n",
    "report_path = os.path.join(args['save_dir'], 'Test_classification_report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(formatted_report)\n",
    "print(f\"Report salvato in: {report_path}\")\n",
    "\n",
    "# ROC per ogni classe\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    y_true = (labels_multi_multi == i).astype(int)\n",
    "    y_score = proba_test_multi[:, i]\n",
    "    \n",
    "    if len(set(y_true)) > 1:  # Calcola solo se ci sono sia 0 che 1 nella classe\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_auc_dict[class_name]:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonale\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve per Classe')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Salva il plot per le classi\n",
    "roc_classes_path = os.path.join(args['save_dir'], 'Test_roc_curve_classes.png')\n",
    "plt.savefig(roc_classes_path)\n",
    "plt.close()\n",
    "print(f\"ROC Curve per classe salvata in: {roc_classes_path}\")\n",
    "\n",
    "# Macro e Weighted ROC\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Macro-Average Curve\n",
    "fpr_macro = np.linspace(0, 1, 100)\n",
    "tpr_macro = np.zeros_like(fpr_macro)\n",
    "for i in range(len(class_names)):\n",
    "    y_true = (labels_multi_multi == i).astype(int)\n",
    "    y_score = proba_test_multi[:, i]\n",
    "    \n",
    "    if len(set(y_true)) > 1:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        tpr_interp = np.interp(fpr_macro, fpr, tpr)  # Interpolazione\n",
    "        tpr_macro += tpr_interp\n",
    "tpr_macro /= len(class_names)\n",
    "auc_macro_curve = auc(fpr_macro, tpr_macro)\n",
    "plt.plot(fpr_macro, tpr_macro, 'r--', label=f\"Macro-Average ROC (AUC = {auc_macro_curve:.4f})\")\n",
    "\n",
    "# Weighted-Average Curve\n",
    "fpr_weighted = np.linspace(0, 1, 100)\n",
    "tpr_weighted = np.zeros_like(fpr_weighted)\n",
    "weights = [sum(labels_multi_multi == i) for i in range(len(class_names))]  # Numero di esempi per classe\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    y_true = (labels_multi_multi == i).astype(int)\n",
    "    y_score = proba_test_multi[:, i]\n",
    "    \n",
    "    if len(set(y_true)) > 1:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        tpr_interp = np.interp(fpr_weighted, fpr, tpr)  # Interpolazione\n",
    "        tpr_weighted += tpr_interp * weights[i]\n",
    "tpr_weighted /= sum(weights)\n",
    "auc_weighted_curve = auc(fpr_weighted, tpr_weighted)\n",
    "plt.plot(fpr_weighted, tpr_weighted, 'g--', label=f\"Weighted-Average ROC (AUC = {auc_weighted_curve:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonale\n",
    "plt.xlabel('Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Macro e Weighted ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Salva il plot per Macro e Weighted\n",
    "roc_macro_weighted_path = os.path.join(args['save_dir'], 'Test_roc_curve_macro_weighted.png')\n",
    "plt.savefig(roc_macro_weighted_path)\n",
    "plt.close()\n",
    "print(f\"Macro e Weighted ROC Curve salvata in: {roc_macro_weighted_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE to represent multidimensional samples in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_tsne(model, val_loader, device):\n",
    "    print('Start validation...')\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels_multi, labels_bin in tqdm(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            multiclass_output, binary_output = model(inputs)\n",
    "            features = model.features\n",
    "\n",
    "            all_labels.extend(labels_multi.cpu().numpy())\n",
    "            all_features.extend(features.cpu().numpy())\n",
    "            #print(\"all_features:\", len(all_features))\n",
    "\n",
    "    return np.array(all_labels), np.array(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = args[\"device\"]\n",
    "model_path = os.path.join(args['save_dir'], 'model_best_test.pt')\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definire una funzione hook per memorizzare le features\n",
    "def hook_fn(module, input, output):\n",
    "    # Memorizza l'input (features in input al layer)\n",
    "    model.features = input[0]\n",
    "\n",
    "# Registrare l'hook al layer desiderato (in questo caso, il layer finale self.base)\n",
    "hook = model.dropout.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels, all_features = validate_tsne(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_features) # data.data, columns=data.feature_names)\n",
    "labels = all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize t-SNE with appropriate parameters\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=0)\n",
    "\n",
    "# Fit and transform the data\n",
    "tsne_results = tsne.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = list(class_mapping.keys())\n",
    "colors = plt.cm.tab10(range(7))\n",
    "markers = ['>', 'o', '>', '>', 'o', 'o', 'o'] \n",
    "\n",
    "# Create a DataFrame for the results\n",
    "tsne_df = pd.DataFrame(tsne_results, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_df['label'] = labels\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    # Filtra i dati per la classe corrente\n",
    "    subset = tsne_df[tsne_df['label'] == i]\n",
    "    plt.scatter(subset['TSNE1'], subset['TSNE2'], c=[colors[i]], marker=markers[i], label=class_name)\n",
    "\n",
    "# Aggiungi la legenda\n",
    "plt.legend()\n",
    "plt.xlabel('TSNE1')\n",
    "plt.ylabel('TSNE2')\n",
    "plt.title('t-SNE visualization of Melanoma dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Skin_classifier.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1370616,
     "sourceId": 2275763,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4505962,
     "sourceId": 7715456,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4505965,
     "sourceId": 7715461,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4505966,
     "sourceId": 7715463,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4505982,
     "sourceId": 7715482,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PyTorch 2.3.0 (Python 3.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
